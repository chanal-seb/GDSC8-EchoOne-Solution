{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec679c32-2ad8-4b65-8589-0dc11bb76c1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: strands-agents[mistral] in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.52)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.52)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (0.17.0)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.19.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.38.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (6.0.0)\n",
      "Requirement already satisfied: mistralai>=1.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.9.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.5.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.4.3)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.37.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.59b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (0.59b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (0.59b0)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.27.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (0.2.2)\n",
      "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (2.2.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (6.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (8.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents[mistral] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bfd972d-da65-48b0-80de-278955331415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key found, we're ready to roll\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import boto3\n",
    "import requests\n",
    "\n",
    "import pprint\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, TypeVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pydantic for structured data\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands for AI agents\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "# AWS authentication\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import (\n",
    "    save_json,\n",
    "    read_json,\n",
    "    load_file_content,\n",
    "    get_job_paths,\n",
    "    get_training_paths,\n",
    "    sanity_check,\n",
    "\tchat_with_persona,\n",
    "    track_api_call,  # Cost tracking from utils\n",
    "    print_cost_summary,  # Cost summary from utils\n",
    "    reset_cost_tracker  # Reset cost tracker from utils\n",
    ")\n",
    "\n",
    "from src.my_utils import (\n",
    "    display_markdown_file,\n",
    "    call_mistral,\n",
    "    get_agent,\n",
    "    batch_extract,\n",
    "    send_message_to_chat\n",
    ")\n",
    "\n",
    "from src.models.persona_info import PersonaInfo\n",
    "\n",
    "from src.models.interview_info import(\n",
    "    InterviewInfo,\n",
    "    InverviewQualityInfo,\n",
    "    InterviewAgentMessage\n",
    ")\n",
    "from src.prompts.interview_prompt import(\n",
    "    TRAINING_EXTENSION_INTERVIEW_PROMPT,\n",
    "    TRAINING_EXTENSION_INTERVIEW_QUALITY_CHECK_PROMPT\n",
    ")\n",
    "\n",
    "# Load API key from .env file\n",
    "dotenv.load_dotenv(\"../env\")\n",
    "\n",
    "# Check if we're good to go\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"âŒ No MISTRAL_API_KEY found!\")\n",
    "    print(\"Create an env file with your API key\")\n",
    "else:\n",
    "    print(\"âœ… API key found, we're ready to roll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8552d20-7d4e-415f-b967-ea120c30c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TURNS_IN_INTERVIEW = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f6e9d9-3e72-463e-b8ab-791e4256e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PERSONAS_INFO_DIR = Path('../data_personas_info')\n",
    "DATA_JOBS_DIR = Path('../data_jobs')\n",
    "DATA_TRAININGS_DIR = Path('../data_trainings')\n",
    "DATA_INTERVIEWS_DIR = Path('../data_interviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c9ea1f-dac7-40bc-a92b-1e03617d9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas_info_data_version version: v14\n",
      "job_data_version version: v4\n",
      "training_data_version version: v7\n",
      "interview_data_version version: v8\n"
     ]
    }
   ],
   "source": [
    "with open(\"../src/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "personas_info_data_version = config[\"personas_info_data_version\"]\n",
    "print(f\"personas_info_data_version version: {personas_info_data_version}\")\n",
    "\n",
    "job_data_version = config[\"job_data_version\"]\n",
    "print(f\"job_data_version version: {job_data_version}\")\n",
    "\n",
    "training_data_version = config[\"training_data_version\"]\n",
    "print(f\"training_data_version version: {training_data_version}\")\n",
    "\n",
    "interview_data_version = config[\"interview_data_version\"]\n",
    "print(f\"interview_data_version version: {interview_data_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37e38fcd-1a0d-4960-82a9-ee9479b7a641",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"map_clusters_jobs_{job_data_version}.json\"\n",
    "save_path = DATA_JOBS_DIR / filename\n",
    "jobs_map = read_json(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d53eed6-3264-4dd1-bd54-b8e1c457780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 12 skills domains\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load skills domains data\n",
    "filename = f\"final_map_clusters_trainings_{training_data_version}.json\"\n",
    "save_path = DATA_TRAININGS_DIR / filename\n",
    "trainings_map = read_json(save_path)\n",
    "\n",
    "print(f\"âœ… Loaded {len(trainings_map)} skills domains\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64cac2d-4e0f-46c2-9b12-6d0a1d410ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 100 personas\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load Personas data\n",
    "filename = f\"final_with_jobs_trainings_personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "\n",
    "personas_data = read_json(personas_save_path)\n",
    "\n",
    "# Convert to PersonaInfo objects\n",
    "personas = {\n",
    "    pid: PersonaInfo.model_validate_json(data)\n",
    "    for pid, data in personas_data.items()\n",
    "}\n",
    "\n",
    "print(f\"âœ… Loaded {len(personas)} personas\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6c29c-70d4-4f4e-acce-42ccfc861cf7",
   "metadata": {},
   "source": [
    "# Perform interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77e39d4-8740-4770-8afb-c442e70e2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_persona_interview(\n",
    "    persona_id: str,\n",
    "    domains_str: str,\n",
    "    conversation_id: str = None,\n",
    "    max_turns: int = 5,\n",
    "    model: str = \"mistral-medium-latest\",\n",
    "    print_conversation: bool = False\n",
    ") -> List[str]:\n",
    "    \"\"\"Interview a persona and return conversation transcript\"\"\"\n",
    "    \n",
    "    interview = InterviewInfo()\n",
    "    \n",
    "    # prompt = INITIAL_INTERVIEW_PROMPT\n",
    "    prompt = TRAINING_EXTENSION_INTERVIEW_PROMPT\n",
    "    \n",
    "    interview_agent = get_agent(prompt, model_id=model)\n",
    "\n",
    "    # Start with greeting\n",
    "    agent_message = \"In a single sentence, which domains you are interested in to find trainings from following list:\\n\"\n",
    "    agent_message += domains_str\n",
    "    agent_message += \"If none of them or not interested by a training, just say it\"\n",
    "\n",
    "    # print(conversation_id)\n",
    "    # print(prompt)\n",
    "    # print(agent_message)\n",
    "    # return None\n",
    "    \n",
    "    if print_conversation:\n",
    "        print(f\"Assistant: {agent_message}\")\n",
    "    interview.interview.append(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    # Conduct interview\n",
    "    for turn in range(max_turns):\n",
    "        resp = send_message_to_chat(agent_message, persona_id, conversation_id)\n",
    "        print(resp)\n",
    "\n",
    "        if resp is None:\n",
    "            break\n",
    "\n",
    "        user_response, conversation_id = resp\n",
    "        interview.conversation_id = conversation_id\n",
    "        interview.interview.append(f\"User: {user_response}\")\n",
    "        if print_conversation:\n",
    "            print(f\"User: {user_response}\")\n",
    "\n",
    "        # Generate next question\n",
    "        conversation_str = '\\n'.join(interview.interview)\n",
    "        agent_response = interview_agent.structured_output(output_model=InterviewAgentMessage, prompt=conversation_str)\n",
    "        # agent_response = interview_agent.structured_output(output_model=InterviewAgentMessage, user_response)\n",
    "\n",
    "        # Track cost (using utils.py function)\n",
    "        # track_api_call(agent_response, model)\n",
    "\n",
    "        if agent_response.conversation_finished is True:\n",
    "            break\n",
    "            \n",
    "        agent_message = agent_response.message\n",
    "        interview.interview.append(f\"Assistant: {agent_message}\")\n",
    "        if print_conversation:\n",
    "            print(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    return interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011eb042-a2fe-49a3-8fc1-07ff9ecedc7b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    persona_id = 'persona_001'\n",
    "\n",
    "    conversation_id = None\n",
    "    # print(conversation_id)\n",
    "    # print(conversation)\n",
    "\n",
    "    domains_str = \"\"\n",
    "    for domain in trainings_map:\n",
    "        domains_str += f\"- {domain}\" + \"\\n\"\n",
    "\n",
    "    print(domains_str)\n",
    "\n",
    "    # interview = conduct_persona_interview(\n",
    "    #     persona_id,\n",
    "    #     domains_str,\n",
    "    #     conversation_id=conversation_id,\n",
    "    #     max_turns=5,\n",
    "    #     model=\"mistral-small-latest\",\n",
    "    #     print_conversation=True\n",
    "    # )\n",
    "\n",
    "    # print(interview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d75e12-da00-4d6f-baf4-0087f51dd86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona_007\n",
      "('The brush only listens to the whisper of colors.', '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_007#2025-10-27T12:13:52')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 6/100 [00:05<01:20,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Interview all personas\n",
    "#persona_ids = [f'persona_{i:03}' for i in range(1, 4)]\n",
    "persona_ids = [f'persona_{i:03}' for i in range(1, 101)]\n",
    "\n",
    "# personas_save_path = SUBMISSION_DIR / 'personas.json'\n",
    "filename = f\"training_domain_extension_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "if not interviews_save_path.exists():\n",
    "    save_json(interviews_save_path, {})\n",
    "interviews = read_json(interviews_save_path)\n",
    "\n",
    "# Track how many new personas we process\n",
    "new_personas_processed = 0\n",
    "\n",
    "for persona_id in tqdm(persona_ids):\n",
    "\n",
    "    if persona_id in interviews:\n",
    "        continue\n",
    "\n",
    "    persona_info = personas[persona_id]\n",
    "    if persona_info.recommendation_type != 'trainings_only':\n",
    "        continue\n",
    "\n",
    "    print(persona_id)\n",
    "    conversation_id = None\n",
    "\n",
    "    new_personas_processed += 1\n",
    "\n",
    "    domains_str = \"\"\n",
    "    for domain in trainings_map:\n",
    "        domains_str += f\"- {domain}\" + \"\\n\"\n",
    "\n",
    "    # Interview\n",
    "    conversation = conduct_persona_interview(\n",
    "        persona_id,\n",
    "        domains_str,\n",
    "        conversation_id=conversation_id,\n",
    "        max_turns=3,\n",
    "        print_conversation=False)\n",
    "    interviews[persona_id] = conversation.model_dump()\n",
    "\n",
    "    # Save every interview\n",
    "    if len(interviews) % 1 == 0:\n",
    "        save_json(interviews_save_path, interviews)\n",
    "\n",
    "    # Show cost update every 20 personas\n",
    "    # if new_personas_processed > 0 and new_personas_processed % 20 == 0:\n",
    "    #     print(f\"\\nðŸ’° Cost update after {new_personas_processed} new personas:\")\n",
    "    #     print_cost_summary()\n",
    "    #     print()\n",
    "\n",
    "    if new_personas_processed > 0:break\n",
    "\n",
    "save_json(interviews_save_path, interviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef40c84a-c533-4a07-a291-8289b5f59a12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# For Debug Only\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867ec51-9b72-43fd-b988-81027cefdf89",
   "metadata": {},
   "source": [
    "# Redo interview of Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14f58994-7732-4c40-b190-f7837c818da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: In a single sentence, which domains you are interested in to find trainings from following list:\n",
      "- Financial Risk Management And Compliance\n",
      "- Electrical And Electronic Systems Engineering\n",
      "- Food Safety And Management\n",
      "- Fiber And Paper Industry Operations\n",
      "- Industrial Equipment Maintenance And Optimization\n",
      "- Procurement And Supply Chain Management\n",
      "- Hospitality And Tourism Management\n",
      "- Legal Practice And Advocacy\n",
      "- Maritime And Port Operations Management\n",
      "- Visual And Artistic Skills\n",
      "- Information Management And Digital Security\n",
      "- Live Event Technical Management\n",
      "If none of them or not interested by a training, just say it\n",
      "('The one about Industrial Equipment Maintenance and Optimization sounds cool because of the machines!', '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_025#2025-10-30T20:26:15')\n",
      "User: The one about Industrial Equipment Maintenance and Optimization sounds cool because of the machines!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13828/3774725164.py:48: DeprecationWarning: Agent.structured_output method is deprecated. You should pass in `structured_output_model` directly into the agent invocation. see: https://strandsagents.com/latest/documentation/docs/user-guide/concepts/agents/structured-output/\n",
      "  agent_response = interview_agent.structured_output(output_model=InterviewAgentMessage, prompt=conversation_str)\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    persona_id = 'persona_025'\n",
    "\n",
    "    #filename = f\"training_domain_extension_interviews_{interview_data_version}.json\"\n",
    "    #interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "    #interviews = read_json(interviews_save_path)\n",
    "    #conversation_id = None\n",
    "\n",
    "    filename = f\"full_interviews_{persona_id}.json\"\n",
    "    interview_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "    interview = read_json(interview_save_path)\n",
    "    conversation_id = interview['conversation_id']\n",
    "    \n",
    "    domains_str = \"\"\n",
    "    for domain in trainings_map:\n",
    "        domains_str += f\"- {domain}\" + \"\\n\"\n",
    "\n",
    "    # Interview\n",
    "    conversation = conduct_persona_interview(\n",
    "        persona_id,\n",
    "        domains_str,\n",
    "        conversation_id=conversation_id,\n",
    "        max_turns=5,\n",
    "        print_conversation=True)\n",
    "\n",
    "    new_interview = conversation.model_dump()\n",
    "    interview['interview'].extend(new_interview['interview'])\n",
    "    save_json(interview_save_path, interview)\n",
    "\n",
    "    #interviews[persona_id] = conversation.model_dump()\n",
    "    \n",
    "    #print(conversation)\n",
    "    #save_json(interviews_save_path, interviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf847e69-4c71-4365-82b1-96e7dd735618",
   "metadata": {},
   "source": [
    "# Check interview qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9dde91c-a633-45b1-9533-0e5d5c9f9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_interview_quality(\n",
    "    interview: str,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt: bool = False\n",
    ") -> InverviewQualityInfo:\n",
    "    prompt = TRAINING_EXTENSION_INTERVIEW_QUALITY_CHECK_PROMPT.format(\n",
    "        interview=interview\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "    \n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=InverviewQualityInfo, prompt=prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb207343-cbf1-4866-995d-4a10d61d0bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"training_domain_extension_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a425eb-546a-4e03-968f-a2b996e4755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"final_with_jobs_trainings_personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "personas_data = read_json(personas_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82ba1074-4158-4fa9-b794-c459272822e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation_id': '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_046#2025-10-23T07:09:51', 'interview': ['Assistant: In a single sentence, which domains you are interested in to find trainings from following list:\\n- Financial Risk Management And Compliance\\n- Electrical And Electronic Systems Engineering\\n- Food Safety And Management\\n- Fiber And Paper Industry Operations\\n- Industrial Equipment Maintenance And Optimization\\n- Procurement And Supply Chain Management\\n- Hospitality And Tourism Management\\n- Legal Practice And Advocacy\\n- Maritime And Port Operations Management\\n- Visual And Artistic Skills\\n- Information Management And Digital Security\\n- Live Event Technical Management\\nIf none of them or not interested by a training, just say it', 'User: I think Legal Practice and Advocacyâ€¦ but maybe not the others, Iâ€™m not sureâ€¦']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:00<00:00, 59.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation_id': '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_053#2025-10-23T07:09:57', 'interview': ['Assistant: In a single sentence, which domains you are interested in to find trainings from following list:\\n- Financial Risk Management And Compliance\\n- Electrical And Electronic Systems Engineering\\n- Food Safety And Management\\n- Fiber And Paper Industry Operations\\n- Industrial Equipment Maintenance And Optimization\\n- Procurement And Supply Chain Management\\n- Hospitality And Tourism Management\\n- Legal Practice And Advocacy\\n- Maritime And Port Operations Management\\n- Visual And Artistic Skills\\n- Information Management And Digital Security\\n- Live Event Technical Management\\nIf none of them or not interested by a training, just say it', \"User: I think I'd be interested in Financial Risk Management And Compliance, but I'm not sure if it's too far from accounting and data stuff.\"]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 53/100 [00:01<00:01, 36.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation_id': '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_059#2025-10-23T07:10:05', 'interview': ['Assistant: In a single sentence, which domains you are interested in to find trainings from following list:\\n- Financial Risk Management And Compliance\\n- Electrical And Electronic Systems Engineering\\n- Food Safety And Management\\n- Fiber And Paper Industry Operations\\n- Industrial Equipment Maintenance And Optimization\\n- Procurement And Supply Chain Management\\n- Hospitality And Tourism Management\\n- Legal Practice And Advocacy\\n- Maritime And Port Operations Management\\n- Visual And Artistic Skills\\n- Information Management And Digital Security\\n- Live Event Technical Management\\nIf none of them or not interested by a training, just say it', 'User: Honestly, none of those really catch my eyeâ€”I just wanna find trainings in Insurance, you know? Thatâ€™s the only thing Iâ€™m focused on right now.']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 59/100 [00:01<00:01, 25.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation_id': '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_067#2025-10-23T19:50:09', 'interview': ['Assistant: In a single sentence, which domains you are interested in to find trainings from following list:\\n- Financial Risk Management And Compliance\\n- Electrical And Electronic Systems Engineering\\n- Food Safety And Management\\n- Fiber And Paper Industry Operations\\n- Industrial Equipment Maintenance And Optimization\\n- Procurement And Supply Chain Management\\n- Hospitality And Tourism Management\\n- Legal Practice And Advocacy\\n- Maritime And Port Operations Management\\n- Visual And Artistic Skills\\n- Information Management And Digital Security\\n- Live Event Technical Management\\nIf none of them or not interested by a training, just say it', 'User: Honestly, the only one that kinda catches my eye is Financial Risk Management And Compliance, but Iâ€™m really just looking for something focused on Policy Implementation in banking or insurance.']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:02<00:01, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation_id': '39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_092#2025-10-23T07:10:08', 'interview': ['Assistant: In a single sentence, which domains you are interested in to find trainings from following list:\\n- Financial Risk Management And Compliance\\n- Electrical And Electronic Systems Engineering\\n- Food Safety And Management\\n- Fiber And Paper Industry Operations\\n- Industrial Equipment Maintenance And Optimization\\n- Procurement And Supply Chain Management\\n- Hospitality And Tourism Management\\n- Legal Practice And Advocacy\\n- Maritime And Port Operations Management\\n- Visual And Artistic Skills\\n- Information Management And Digital Security\\n- Live Event Technical Management\\nIf none of them or not interested by a training, just say it', 'User: Only Culture and Document Management, but if I gotta pick from that list, then Information Management and Digital Securityâ€”itâ€™s the closest to what I need for digital archiving and data security trainings.']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:03<00:00, 26.62it/s]\n"
     ]
    }
   ],
   "source": [
    "cache_period = 5\n",
    "\n",
    "filename = f\"quality_training_domain_extension_interviews__{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "if not save_path.exists():\n",
    "    save_json(save_path, {})\n",
    "quality_interviews = read_json(save_path)\n",
    "\n",
    "new_items_processed = 0\n",
    "for persona_id in tqdm(personas_data):\n",
    "    persona_data_dict = json.loads(personas_data[persona_id])\n",
    "\n",
    "    if persona_data_dict['recommendation_type'] != 'trainings_only':\n",
    "        continue\n",
    "\n",
    "    if persona_id in quality_interviews:\n",
    "        quality = json.loads(quality_interviews[persona_id])\n",
    "        if quality['quality_level'] == 'OK':\n",
    "            continue\n",
    "\n",
    "    if persona_id not in interviews:\n",
    "        quality_data = {\n",
    "            'quality_level': 'NOK',\n",
    "            'rationale': 'interview missing'\n",
    "        }\n",
    "        quality = InverviewQualityInfo(**quality_data)\n",
    "        quality_str = json.dumps(quality.model_dump(), ensure_ascii=False)\n",
    "        quality_interviews[persona_id] = quality_str\n",
    "        save_json(save_path, quality_interviews)\n",
    "        continue\n",
    "\n",
    "    new_items_processed = new_items_processed + 1\n",
    "\n",
    "    interview = interviews[persona_id]['interview']\n",
    "\n",
    "    interview_str = \"\\n\".join(interview)\n",
    "    # print(interview_str)\n",
    "\n",
    "    quality = check_interview_quality(\n",
    "        interview_str,\n",
    "        print_prompt=False\n",
    "    )\n",
    "    quality_str = json.dumps(quality.model_dump(), ensure_ascii=False)\n",
    "\n",
    "    quality_interviews[persona_id] = quality_str\n",
    "\n",
    "    if new_items_processed % cache_period == 0:\n",
    "        save_json(save_path, quality_interviews)\n",
    "\n",
    "    #if new_items_processed > 0:break\n",
    "\n",
    "save_json(save_path, quality_interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "529ccf61-a664-4724-b6e4-f1a2c988e5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona_059\n",
      "The user did not provide information about any of the listed training domains. The user expressed interest in a domain not listed in the provided options.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "filename = f\"quality_training_domain_extension_interviews__{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "quality_interviews = read_json(save_path)\n",
    "\n",
    "for persona_id in quality_interviews:\n",
    "    quality = json.loads(quality_interviews[persona_id])\n",
    "    if quality['quality_level'] != 'OK':\n",
    "        print(persona_id)\n",
    "        print(quality['rationale'])\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50b3dc-0bc4-4b74-a7c6-2cfea74d3f24",
   "metadata": {},
   "source": [
    "# Redo interview of a Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe28935f-3861-4c58-9282-04060a6eb093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Conduct Interview...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conduct_persona_interview() missing 1 required positional argument: 'domains_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Interview\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸŽ¤ Conduct Interview...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m conversation \u001b[38;5;241m=\u001b[39m \u001b[43mconduct_persona_interview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpersona_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_conversation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(conversation)\n",
      "\u001b[0;31mTypeError\u001b[0m: conduct_persona_interview() missing 1 required positional argument: 'domains_str'"
     ]
    }
   ],
   "source": [
    "persona_id = \"persona_009\"\n",
    "\n",
    "# Interview\n",
    "print(\"ðŸŽ¤ Conduct Interview...\")\n",
    "conversation = conduct_persona_interview(persona_id, max_turns=10, print_conversation=True)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e2eef5-73ca-436b-be95-e267b5b16dd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conversation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m interviews_save_path \u001b[38;5;241m=\u001b[39m DATA_INTERVIEWS_DIR \u001b[38;5;241m/\u001b[39m filename\n\u001b[1;32m      3\u001b[0m interviews \u001b[38;5;241m=\u001b[39m read_json(interviews_save_path)\n\u001b[0;32m----> 4\u001b[0m interviews[persona_id] \u001b[38;5;241m=\u001b[39m \u001b[43mconversation\u001b[49m\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m      5\u001b[0m save_json(interviews_save_path, interviews)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conversation' is not defined"
     ]
    }
   ],
   "source": [
    "filename = f\"job_extension_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)\n",
    "interviews[persona_id] = conversation.model_dump()\n",
    "save_json(interviews_save_path, interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59416f13-8eba-4004-907d-081bac4f843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaef335b-47de-4657-8bf7-9aec70fedf51",
   "metadata": {},
   "source": [
    "# Translate interviews in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c804d-0058-4325-8b20-4f268397cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_interview(\n",
    "    interview,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt=False\n",
    ") -> InterviewInfo:\n",
    "\n",
    "    prompt = TRANSLATE_INTERVIEW_PROMPT.format(\n",
    "        interview=interview\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=InterviewInfo, prompt=prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf0145f-c97b-4f09-9f0f-32e650186e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = f\"interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8be107-e323-473c-b187-3b4ae4086ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_period = 5\n",
    "\n",
    "filename = f\"en_interviews_{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "if not save_path.exists():\n",
    "    save_json(save_path, {})\n",
    "en_interviews = read_json(save_path)\n",
    "\n",
    "\n",
    "new_items_processed = 0\n",
    "for interview_id in tqdm(interviews):\n",
    "    if interview_id in en_interviews:\n",
    "        continue\n",
    "\n",
    "    new_items_processed = new_items_processed + 1\n",
    "    \n",
    "    interview = interviews[interview_id]\n",
    "\n",
    "    translated_interview = translate_interview(interview, print_prompt=False)\n",
    "    en_interviews[interview_id] = translated_interview.interview\n",
    "\n",
    "    if new_items_processed % cache_period == 0:\n",
    "        save_json(save_path, en_interviews)\n",
    "\n",
    "    # if new_items_processed > 4:break\n",
    "\n",
    "save_json(save_path, en_interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bba8d5-dd70-4e6a-94f8-f6da4ea35b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
