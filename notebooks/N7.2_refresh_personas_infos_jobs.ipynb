{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7aec46e5-52bf-4fcd-b868-63fbab04bf54",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: strands-agents[mistral] in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.13.0)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.52)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.52)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (0.17.0)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.19.0)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (0.59b0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.30.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.38.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (6.0.0)\n",
      "Requirement already satisfied: mistralai>=1.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.9.11)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.5.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.11.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.4.3)\n",
      "Requirement already satisfied: httpx>=0.27.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.28.1)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.25.1)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2.11.0)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.0.2)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.37.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.59b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (0.59b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (0.59b0)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.27.1)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (0.2.2)\n",
      "Requirement already satisfied: invoke<3.0.0,>=2.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (2.2.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (6.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (8.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents[mistral] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76fec45b-aa58-44fb-827c-0175956f2471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key found, we're ready to roll\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import boto3\n",
    "import requests\n",
    "\n",
    "import pprint\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, TypeVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Pydantic for structured data\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands for AI agents\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "# AWS authentication\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import (\n",
    "    save_json,\n",
    "    read_json,\n",
    "    load_file_content,\n",
    "    get_job_paths,\n",
    "    get_training_paths,\n",
    "    sanity_check,\n",
    "\tchat_with_persona,\n",
    "    track_api_call,  # Cost tracking from utils\n",
    "    print_cost_summary,  # Cost summary from utils\n",
    "    reset_cost_tracker  # Reset cost tracker from utils\n",
    ")\n",
    "\n",
    "from src.my_utils import (\n",
    "    display_markdown_file,\n",
    "    call_mistral,\n",
    "    get_agent,\n",
    "    batch_extract,\n",
    "    compute_stat_for_multi_items\n",
    ")\n",
    "\n",
    "from src.models.interview_info import(\n",
    "    InterviewInfo,\n",
    "    InverviewQualityInfo\n",
    ")\n",
    "from src.models.generic_models import ListOfIds\n",
    "from src.models.job_info import JobInfo\n",
    "from src.models.persona_info import PersonaInfo, PersonaSkills, RecommendationAnalysis\n",
    "from src.models.activity_domain_info import ActivityDomainInfo, ListOfActivityDomains\n",
    "from src.models.skill_domain_info import SkillDomainInfo, ListSkillsDomains\n",
    "from src.prompts.persona_extraction_prompt import (\n",
    "    PERSONA_EXTRACTION_PROMPT,\n",
    "    PERSONA_INITIAL_EXTRACTION_PROMPT,\n",
    "    PERSONA_EXTEND_SKILL_DOMAIN_PROMPT,\n",
    "    PERSONA_SKILL_DOMAINS_CLASSIFICATION_PROMPT,\n",
    "    PERSONA_ACTIVITY_DOMAINS_CLASSIFICATION_PROMPT,\n",
    "    PERSONA_JOBS_EXTRACTION_PROMPT,\n",
    "    PERSONA_JOB_SKILLS_EXTRACTION_PROMPT,\n",
    "    PERSONA_INTEREST_EXTRACTION_PROMPT\n",
    ")\n",
    "\n",
    "# Load API key from .env file\n",
    "dotenv.load_dotenv(\"../env\")\n",
    "\n",
    "# Check if we're good to go\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"âŒ No MISTRAL_API_KEY found!\")\n",
    "    print(\"Create an env file with your API key\")\n",
    "else:\n",
    "    print(\"âœ… API key found, we're ready to roll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e41af00-3ed7-4d1f-8bd0-b16446186248",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_JOBS_DIR = Path('../data_jobs')\n",
    "DATA_TRAININGS_DIR = Path('../data_trainings')\n",
    "DATA_INTERVIEWS_DIR = Path('../data_interviews')\n",
    "DATA_ACTIVITIES_DOMAINS_DIR = Path('../data_activities_domains')\n",
    "DATA_SKILLS_DOMAINS_DIR = Path('../data_skills_domains')\n",
    "DATA_PERSONAS_INFO_DIR = Path('../data_personas_info')\n",
    "DATA_MATCH_JOBS_TRAININGS_DIR = Path('../data_match_jobs_trainings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7b5960a-d12b-4af8-b533-ba27fed5f106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_data_version version: v4\n",
      "training_data_version version: v7\n",
      "interview_data_version version: v8\n",
      "activity_domains_version version: v4\n",
      "personas_info_data_version version: v14\n",
      "skill_domains_version version: v3\n"
     ]
    }
   ],
   "source": [
    "with open(\"../src/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "job_data_version = config[\"job_data_version\"]\n",
    "print(f\"job_data_version version: {job_data_version}\")\n",
    "\n",
    "training_data_version = config[\"training_data_version\"]\n",
    "print(f\"training_data_version version: {training_data_version}\")\n",
    "\n",
    "interview_data_version = config[\"interview_data_version\"]\n",
    "print(f\"interview_data_version version: {interview_data_version}\")\n",
    "\n",
    "activity_domains_version = config[\"activity_domains_version\"]\n",
    "print(f\"activity_domains_version version: {activity_domains_version}\")\n",
    "\n",
    "personas_info_data_version = config[\"personas_info_data_version\"]\n",
    "print(f\"personas_info_data_version version: {personas_info_data_version}\")\n",
    "\n",
    "skill_domains_version = config[\"skill_domains_version\"]\n",
    "print(f\"skill_domains_version version: {skill_domains_version}\")\n",
    "\n",
    "match_jobs_trainings_data_version = f\"{job_data_version}_{training_data_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06806ca7-5fe3-4fb0-a851-57938ac909c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load jobs domains map data\n",
    "filename = f\"map_clusters_jobs_{job_data_version}.json\"\n",
    "save_path = DATA_JOBS_DIR / filename\n",
    "jobs_map = read_json(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb17430b-2038-4b5f-9397-fe62d8395a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 12 skills domains\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load skills domains map data\n",
    "filename = f\"final_map_clusters_trainings_{training_data_version}.json\"\n",
    "save_path = DATA_TRAININGS_DIR / filename\n",
    "trainings_map = read_json(save_path)\n",
    "\n",
    "print(f\"âœ… Loaded {len(trainings_map)} skills domains\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "827a9f4e-adf5-4864-a257-c3d0c2ed8b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 100 personas\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load Personas data\n",
    "filename = f\"job_filtered_personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "\n",
    "initial_personas_data = read_json(personas_save_path)\n",
    "\n",
    "# Convert to PersonaInfo objects\n",
    "personas = {\n",
    "    pid: PersonaInfo.model_validate_json(data)\n",
    "    for pid, data in initial_personas_data.items()\n",
    "}\n",
    "\n",
    "print(f\"âœ… Loaded {len(personas)} personas\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78b68abc-ea17-45f1-b7ee-ca4d4bddc6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 200 jobs\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load jobs data\n",
    "filename = f\"final_jobs_{job_data_version}.json\"\n",
    "jobs_save_path = DATA_JOBS_DIR / filename\n",
    "jobs_data = read_json(jobs_save_path)\n",
    "\n",
    "# Convert to JobInfo objects\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(data)\n",
    "    for job_id, data in jobs_data.items()\n",
    "}\n",
    "\n",
    "print(f\"âœ… Loaded {len(jobs_info)} jobs\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "656ce1b9-56b0-497d-a6a9-e84ffabeb9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"match_jobs_trainings_{match_jobs_trainings_data_version}.json\"\n",
    "save_path = DATA_MATCH_JOBS_TRAININGS_DIR / filename\n",
    "job_training_map = read_json(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e6888d8-75bd-4526-beb0-15328f630bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 52 interviews\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "filename = f\"jobs_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)\n",
    "\n",
    "# Convert to InterviewInfo objects\n",
    "interviews_info = {}\n",
    "for id in interviews:\n",
    "    #print(id)\n",
    "    interviews_info[id] = InterviewInfo(**interviews[id])\n",
    "\n",
    "print(f\"âœ… Loaded {len(interviews_info)} interviews\")\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009ac186-2682-4435-a2f8-78f0ef04f69a",
   "metadata": {},
   "source": [
    "# Persona info parsing loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee08ce76-5abb-4910-a488-90475ad3adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jobs_info(\n",
    "    conversation: List[str],\n",
    "    jobs_str: str,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt=False\n",
    ") -> ListOfIds:\n",
    "    \"\"\"Extract persona info from conversation using Persona Extraction Agent\"\"\"\n",
    "   \n",
    "    text = '\\n'.join(conversation)\n",
    "    #print(text)\n",
    "\n",
    "    prompt = PERSONA_JOBS_EXTRACTION_PROMPT.format(\n",
    "        conversation=text,\n",
    "        jobs_list=jobs_str\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "    \n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=ListOfIds, prompt=prompt)\n",
    "\n",
    "    # Track cost\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff52a3eb-a15e-4cab-a3b8-2c6a2007131b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_skills_info(\n",
    "    conversation: List[str],\n",
    "    job_skills_str: str,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt=False\n",
    ") -> PersonaSkills:\n",
    "    \"\"\"Extract persona info from conversation using Persona Extraction Agent\"\"\"\n",
    "   \n",
    "    text = '\\n'.join(conversation)\n",
    "    #print(text)\n",
    "\n",
    "    prompt = PERSONA_JOB_SKILLS_EXTRACTION_PROMPT.format(\n",
    "        conversation=text,\n",
    "        skills_list=job_skills_str\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=PersonaSkills, prompt=prompt)\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(result)\n",
    "        \n",
    "    # Track cost\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91539cbc-a273-4deb-82b5-bcd40d38e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_personas_skills(personas_info_data_version):\n",
    "    filename = f\"personas_info_{personas_info_data_version}.json\"\n",
    "    personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "    personas_data = read_json(personas_save_path)\n",
    "\n",
    "    for persona_id in personas_data:\n",
    "        persona_data = json.loads(personas_data[persona_id])\n",
    "        persona_data['skills'] = {}\n",
    "        personas_data[persona_id] = json.dumps(persona_data, ensure_ascii=False)\n",
    "\n",
    "    save_json(personas_save_path, personas_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76860789-63f7-41e1-a704-62e299812b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_skills_quality(persona_data):\n",
    "    skills = persona_data['skills']\n",
    "\n",
    "    if len(skills) == 0:\n",
    "        issue_with_skills = True\n",
    "    else:\n",
    "        issue_with_skills = False\n",
    "\n",
    "        for domain_skill in skills:\n",
    "            level = skills[domain_skill]\n",
    "            parts = domain_skill.split(\" / \")\n",
    "            if len(parts) < 2:\n",
    "                issue_with_skills = True\n",
    "                print(\"ERROR with skill name format\")\n",
    "                break\n",
    "\n",
    "            domain = parts[0]\n",
    "            skill = parts[1]\n",
    "            if domain not in trainings_map:\n",
    "                issue_with_skills = True\n",
    "                print(f\"ERROR with domain name : {domain}\")\n",
    "                break\n",
    "\n",
    "            if skill not in trainings_map[domain]:\n",
    "                issue_with_skills = True\n",
    "                print(f\"ERROR with skill name : {skill}\")\n",
    "                break\n",
    "\n",
    "            if level not in ['None', 'Basic', 'Intermediate', 'Advanced']:\n",
    "                issue_with_skills = True\n",
    "                print(f\"ERROR with level name : {level}\")\n",
    "                break\n",
    "\n",
    "    return issue_with_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e945ced-292e-4a45-9173-8ee331b27eea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_LOOPS = 1\n",
    "cache_period = 5\n",
    "\n",
    "# Prepare personas info\n",
    "filename = f\"final_with_jobs_trainings_personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "if not personas_save_path.exists():\n",
    "    save_json(personas_save_path, {})\n",
    "personas_data = read_json(personas_save_path)\n",
    "\n",
    "new_items_processed = 0\n",
    "\n",
    "print(\"START CLASSIFICATION LOOP\")\n",
    "for i in range(MAX_LOOPS):\n",
    "    print(\"ITERATE CLASSIFICATION LOOP\")\n",
    "\n",
    "    filt_personas_ids = []\n",
    "    for persona_id in initial_personas_data:\n",
    "        if persona_id not in personas_data:\n",
    "            persona_data = json.loads(initial_personas_data[persona_id])\n",
    "            filt_personas_ids.append(persona_id)\n",
    "        else:\n",
    "            persona_data = json.loads(initial_personas_data[persona_id])\n",
    "            if persona_data['recommendation_type'] == 'jobs_trainings':\n",
    "                persona_data = json.loads(personas_data[persona_id])\n",
    "                issue_with_skills = compute_skills_quality(persona_data)\n",
    "                if issue_with_skills is True:\n",
    "                    filt_personas_ids.append(persona_id)\n",
    "\n",
    "        #print(persona_id)\n",
    "        #print(persona_data)\n",
    "        personas_data[persona_id] = json.dumps(persona_data, ensure_ascii=False)\n",
    "\n",
    "    print(f'Personas to process: {filt_personas_ids}')\n",
    "\n",
    "    if len(filt_personas_ids) == 0:\n",
    "        break\n",
    "\n",
    "    #print(filt_personas_ids)\n",
    "    #print(personas_data['persona_004'])\n",
    "    \n",
    "    # Reset cost tracker if starting fresh\n",
    "    # if len(persona_infos) == 0:\n",
    "    #     reset_cost_tracker()\n",
    "    #     print(\"ðŸ’° Starting fresh - cost tracker reset\")\n",
    "\n",
    "    # Track how many new personas we process\n",
    "    new_personas_processed = 0\n",
    "\n",
    "    for persona_id in tqdm(filt_personas_ids):\n",
    "        if persona_id not in interviews_info:\n",
    "            continue\n",
    "\n",
    "        #print(persona_id)\n",
    "        \n",
    "        new_personas_processed += 1\n",
    "        conversation = interviews_info[persona_id].interview\n",
    "        # print(conversation)\n",
    "\n",
    "        print_prompt = False\n",
    "        #if new_personas_processed == 1:\n",
    "        #    print_prompt = True\n",
    "\n",
    "        persona_data = json.loads(personas_data[persona_id])\n",
    "\n",
    "        jobs_str = \"\"\n",
    "        for job_id in persona_data['proposed_job_ids']:\n",
    "            jobs_str += f\"- '{job_id}'\" + \"\\n\"\n",
    "    \n",
    "        result = extract_jobs_info(\n",
    "            interviews_info[persona_id].interview,\n",
    "            jobs_str,\n",
    "            model=\"mistral-medium-latest\",\n",
    "            print_prompt=print_prompt\n",
    "        )\n",
    "\n",
    "        #print(result)\n",
    "        #persona_data['selected_job_ids'] = result.list_of_ids\n",
    "\n",
    "        if 'NOT_INTERESTED' in result.list_of_ids:\n",
    "            persona_data['recommendation_type'] = 'trainings_only'\n",
    "        else:\n",
    "            job_skills_str = \"\"\n",
    "            for job_id in persona_data['proposed_job_ids']:\n",
    "                job_trainings = job_training_map[job_id]\n",
    "                for training in job_trainings:\n",
    "                    job_skills_str += f\"- {training} : {job_trainings[training]}\" + \"\\n\"\n",
    "    \n",
    "            # print(job_skills_str)\n",
    "            # print(interviews_info[persona_id].interview)\n",
    "    \n",
    "            result = extract_skills_info(\n",
    "                interviews_info[persona_id].interview,\n",
    "                job_skills_str,\n",
    "                model=\"mistral-medium-latest\",\n",
    "                print_prompt=print_prompt\n",
    "            )\n",
    "    \n",
    "            #print(result)\n",
    "            #persona_data = json.loads(personas_data[persona_id])\n",
    "            persona_data['skills'] = result.skills\n",
    "            \n",
    "        personas_data[persona_id] = json.dumps(persona_data, ensure_ascii=False)\n",
    "        # print(persona_data)\n",
    "\n",
    "        # Save every 5 personas\n",
    "        if new_personas_processed % 5 == 0:\n",
    "            save_json(personas_save_path, personas_data)\n",
    "\n",
    "        # Show cost update every 20 personas\n",
    "        if new_personas_processed > 0 and new_personas_processed % 20 == 0:\n",
    "            print(f\"\\nðŸ’° Cost update after {new_personas_processed} new personas:\")\n",
    "            print_cost_summary()\n",
    "            print()\n",
    "\n",
    "        # if new_personas_processed > 4:break\n",
    "\n",
    "save_json(personas_save_path, personas_data)\n",
    "\n",
    "# Convert to PersonaInfo objects\n",
    "# personas = {\n",
    "#     pid: PersonaInfo.model_validate_json(data)\n",
    "#     for pid, data in persona_infos.items()\n",
    "# }\n",
    "\n",
    "# print(f\"\\nâœ… Interviewed {len(personas)} personas total ({new_personas_processed} new)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28450dae-add1-4ca1-a081-a346f33c6dbf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# For Debug Only\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "875c69ca-2fea-485c-b14d-d8f65544b23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    persona_id = 'persona_033'\n",
    "    persona_info = personas[persona_id]\n",
    "    print(persona_info.proposed_job_ids)\n",
    "\n",
    "    if len(persona_info.proposed_job_ids) > 0:\n",
    "        jobs_str = \"\"\n",
    "        for job_id in persona_info.proposed_job_ids:\n",
    "            jobs_str += f\"- '{job_id}'\" + \"\\n\"\n",
    "\n",
    "        # print(interviews_info[persona_id].interview)\n",
    "\n",
    "        result = extract_jobs_info(\n",
    "            interviews_info[persona_id].interview,\n",
    "            jobs_str,\n",
    "            model=\"mistral-medium-latest\",\n",
    "            print_prompt=True\n",
    "        )\n",
    "\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4eea56da-6ca8-4e0d-b87d-1973f476bd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    persona_id = 'persona_010'\n",
    "    persona_info = personas[persona_id]\n",
    "    print(persona_info.proposed_job_ids)\n",
    "\n",
    "    if len(persona_info.proposed_job_ids) > 0:\n",
    "        job_skills_str = \"\"\n",
    "        for job_id in persona_info.proposed_job_ids:\n",
    "            job_trainings = job_training_map[job_id]\n",
    "            for training in job_trainings:\n",
    "                job_skills_str += f\"- {training} : {job_trainings[training]}\" + \"\\n\"\n",
    "\n",
    "        print(job_skills_str)\n",
    "        # print(interviews_info[persona_id].interview)\n",
    "\n",
    "        result = extract_skills_info(\n",
    "            interviews_info[persona_id].interview,\n",
    "            job_skills_str,\n",
    "            model=\"mistral-medium-latest\",\n",
    "            print_prompt=False\n",
    "        )\n",
    "\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad5ff3dd-245b-43bf-b568-db827fc6d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    reset_personas_skills(personas_info_data_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8251d4d4-bd8a-476e-bf7d-45f21be66515",
   "metadata": {},
   "source": [
    "# Redo persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ccad259a-95b3-4b96-b5e2-2c70e2d56da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list_of_ids=['NOT_INTERESTED'] rationale='The user explicitly mentioned that they are not looking for a job right away. Instead, they are interested in finding training programs to improve their skills and prepare for a future role in tourism.'\n",
      "{'name': '', 'age': 19, 'location': 'Belo Horizonte', 'recommendation_type': 'trainings_only', 'open_to_relocate_for_work': False, 'work_type_preference': 'onsite', 'target_domains': ['Tourism And Hospitality Guest Services'], 'education_level': 'TÃ©cnico', 'years_of_experience': 0, 'skills_domains': [], 'skills': {}, 'languages': ['Portuguese', 'English'], 'goals': 'work with people and languages, practice English more, possibly with travelers, and contribute to hospitality.', 'hard_filtered_jobs_ids': [], 'proposed_job_ids': []}\n"
     ]
    }
   ],
   "source": [
    "persona_id = 'persona_041'\n",
    "\n",
    "filename = f\"final_with_jobs_trainings_personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "personas_data = read_json(personas_save_path)\n",
    "\n",
    "# print(initial_personas_data[persona_id])\n",
    "\n",
    "persona_data = json.loads(initial_personas_data[persona_id])\n",
    "if persona_data['recommendation_type'] != \"jobs_trainings\":\n",
    "    personas_data[persona_id] = initial_personas_data[persona_id]\n",
    "    print(initial_personas_data[persona_id])\n",
    "    save_json(personas_save_path, personas_data)  \n",
    "elif persona_id not in interviews_info:\n",
    "    print('ISSUE')\n",
    "else:\n",
    "    conversation = interviews_info[persona_id].interview\n",
    "    # print(conversation)\n",
    "\n",
    "    persona_data = json.loads(initial_personas_data[persona_id])\n",
    "\n",
    "    jobs_str = \"\"\n",
    "    for job_id in persona_data['proposed_job_ids']:\n",
    "        jobs_str += f\"- '{job_id}'\" + \"\\n\"\n",
    "\n",
    "    result = extract_jobs_info(\n",
    "        interviews_info[persona_id].interview,\n",
    "        jobs_str,\n",
    "        model=\"mistral-medium-latest\",\n",
    "        print_prompt=False\n",
    "    )\n",
    "\n",
    "    print(result)\n",
    "\n",
    "    if 'NOT_INTERESTED' in result.list_of_ids:\n",
    "        persona_data['recommendation_type'] = 'trainings_only'\n",
    "    else:\n",
    "        print('HERE')\n",
    "        job_skills_str = \"\"\n",
    "        for job_id in persona_data['proposed_job_ids']:\n",
    "            job_trainings = job_training_map[job_id]\n",
    "            for training in job_trainings:\n",
    "                job_skills_str += f\"- {training} : {job_trainings[training]}\" + \"\\n\"\n",
    "    \n",
    "        result = extract_skills_info(\n",
    "            interviews_info[persona_id].interview,\n",
    "            job_skills_str,\n",
    "            model=\"mistral-large-latest\",\n",
    "            print_prompt=True\n",
    "        )\n",
    "    \n",
    "        print(result)\n",
    "        \n",
    "        persona_data['skills'] = result.skills\n",
    "\n",
    "    personas_data[persona_id] = json.dumps(persona_data, ensure_ascii=False)\n",
    "    print(persona_data)\n",
    "\n",
    "    save_json(personas_save_path, personas_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4220a4-18f2-48f4-a3ca-4570987e7aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aeb268a-3317-4a23-ad87-c80b03119c0c",
   "metadata": {},
   "source": [
    "# Persona info quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abfa76d-e9cb-4a5e-ba71-890ff537eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"jobs_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)\n",
    "\n",
    "# Convert to InterviewInfo objects\n",
    "interviews_info = {}\n",
    "for id in interviews:\n",
    "    interviews_info[id] = InterviewInfo(**interviews[id])\n",
    "\n",
    "print(f\"âœ… Loaded {len(interviews_info)} interviews\")\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fec073-fdd3-4a74-8a9e-ce1cb6d227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "personas_data = read_json(personas_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "456c9ed6-3ac9-42ff-83bd-59fc71042479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR with level name : \n",
      "ERROR with level name : \n",
      "ERROR with level name : \n",
      "ERROR with skill name format\n",
      "ERROR with skill name format\n",
      "ERROR with skill name format\n",
      "ERROR with skill name format\n",
      "ERROR with level name : Basic to Intermediate\n"
     ]
    }
   ],
   "source": [
    "for persona_id in interviews_info:\n",
    "    persona_data = json.loads(personas_data[persona_id])\n",
    "    compute_skills_quality(persona_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26fdc76-fe05-4795-a3e6-44bd8ecec3f4",
   "metadata": {},
   "source": [
    "# Persona info statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daac4b36-e1e1-4f63-9023-b032ff814cf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = f\"personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "persona_infos = read_json(personas_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "be33d968-96ef-4033-bcc0-2f8a797a720d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age 13: 2 occurrences\n",
      "Age 14: 1 occurrences\n",
      "Age 15: 5 occurrences\n",
      "Age 16: 11 occurrences\n",
      "Age 17: 5 occurrences\n",
      "Age 18: 12 occurrences\n",
      "Age 19: 8 occurrences\n",
      "Age 20: 2 occurrences\n",
      "Age 21: 5 occurrences\n",
      "Age 22: 6 occurrences\n",
      "Age 23: 4 occurrences\n",
      "Age 24: 2 occurrences\n",
      "Age 25: 15 occurrences\n",
      "Age 26: 5 occurrences\n",
      "Age 27: 7 occurrences\n",
      "Age 28: 4 occurrences\n",
      "Age 29: 1 occurrences\n",
      "Age 30: 1 occurrences\n",
      "\n",
      "Recommendation Type Counts:\n",
      "jobs_trainings: 51\n",
      "trainings_only: 38\n",
      "awareness: 11\n",
      "\n",
      "Total count: 100\n",
      "\n",
      "open_to_relocate_for_work Counts:\n",
      "False: 89\n",
      "True: 11\n",
      "\n",
      "Total count: 100\n",
      "\n",
      "Work type preferences Counts:\n",
      "onsite: 74\n",
      ": 12\n",
      "hybrid: 8\n",
      "any: 4\n",
      "remote: 2\n",
      "\n",
      "Total count: 100\n",
      "\n",
      "years_of_experience Counts:\n",
      "0: 40\n",
      "1: 25\n",
      "2: 24\n",
      "3: 11\n",
      "\n",
      "Total count: 100\n",
      "\n",
      "Location Counts:\n",
      "SÃ£o Paulo: 15\n",
      "Recife: 13\n",
      "BrasÃ­lia: 13\n",
      "Rio de Janeiro: 12\n",
      "Belo Horizonte: 11\n",
      "Curitiba: 10\n",
      "Salvador: 9\n",
      "Porto Alegre: 8\n",
      "Fortaleza: 5\n",
      "Brazil: 3\n",
      ": 1\n",
      "\n",
      "Total count: 100\n",
      "\n",
      "target_domains Counts:\n",
      "Electrical And Electronics Systems: 6\n",
      "Cultural Heritage Information Management: 6\n",
      "Manufacturing And Stage Production Operations: 5\n",
      "Paper And Fiber Production And Processing: 5\n",
      "Health Safety And Environment Compliance: 5\n",
      "Insurance Operations And Compliance Management: 5\n",
      "Design Research And Innovation Management: 5\n",
      "Community Development And Engagement: 5\n",
      "Maritime And Port Operations Management: 5\n",
      "Hospitality and Tourism Management: 4\n",
      "Tourism And Guest Services: 4\n",
      "UNKNOWN: 3\n",
      "Visual Arts And Studio Production: 3\n",
      "Industrial Equipment Maintenance and Optimization: 3\n",
      "Electrical and Electronic Systems Engineering: 3\n",
      "Legal Analysis And Support: 3\n",
      "Financial Accounting And Banking Operations: 3\n",
      "Food Production And Quality Management: 2\n",
      "Visual And Artistic Skills: 2\n",
      "Live Event Technical Management: 2\n",
      "Procurement And Supply Chain Management: 2\n",
      "Tourism and Guest Services: 2\n",
      "Food Safety and Management: 1\n",
      "Industrial Equipment Maintenance: 1\n",
      "Fiber And Paper Industry Operations: 1\n",
      "Electrical And Electronic Systems Engineering: 1\n",
      "Procurement and Supply Chain Management: 1\n",
      "Cost Analysis: 1\n",
      "Financial Accounting and Banking Operations: 1\n",
      "Insurance Operations and Compliance Management: 1\n",
      "Health, Safety, and Environment (HSE): 1\n",
      "Maritime and Port Operations Management: 1\n",
      "Maritime Operations: 1\n",
      "\n",
      "Total count: 94\n",
      "\n",
      "skills_domains Counts:\n",
      "Visual And Artistic Skills: 7\n",
      "Industrial Equipment Maintenance And Optimization: 6\n",
      "Hospitality And Tourism Management: 6\n",
      "Financial Risk Management And Compliance: 4\n",
      "Food Safety And Management: 3\n",
      "Electrical And Electronic Systems Engineering: 3\n",
      "Procurement And Supply Chain Management: 3\n",
      "Legal Practice And Advocacy: 3\n",
      "Information Management And Digital Security: 3\n",
      "Maritime And Port Operations Management: 3\n",
      "Live Event Technical Management: 2\n",
      "Fiber And Paper Industry Operations: 1\n",
      "\n",
      "Total count: 44\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nitem_counts, value_counts = compute_stat_for_multi_items(persona_infos, \\'skills\\', include_values=True)\\nprint(\"\\n\" + \"=\"*50)\\nprint(\"\\nSkills Values Counts:\")\\nprint(f\"\\nTotal occurrences: {sum(value_counts.values())}\")\\nprint(f\"Total unique types: {len(value_counts)}\")\\nfor item, count in value_counts.most_common():\\n    print(f\"{item}: {count}\")\\nprint(\"\\nSkills Counts:\")\\nprint(f\"\\nTotal occurrences: {sum(item_counts.values())}\")\\nprint(f\"Total unique types: {len(item_counts)}\")\\nfor item, count in item_counts.most_common():\\n    print(f\"{item}: {count}\")\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Extract ages from the JSON data\n",
    "ages = []\n",
    "for persona in persona_infos.values():\n",
    "    data = json.loads(persona)\n",
    "    if data['age'] > 0:  # Filter out invalid age (0)\n",
    "        ages.append(data['age'])\n",
    "age_counts = Counter(ages)\n",
    "# Print in ascending order of age\n",
    "for age in sorted(age_counts.keys()):\n",
    "    print(f\"Age {age}: {age_counts[age]} occurrences\")\n",
    "\n",
    "# Extract infos from the dictionary\n",
    "recommendation_types = []\n",
    "open_to_relocate_for_work = []\n",
    "work_type_preferences = []\n",
    "locations = []\n",
    "years_of_experiences = []\n",
    "target_domains = []\n",
    "skills_domains = []\n",
    "for persona in persona_infos.values():\n",
    "    data = json.loads(persona)\n",
    "    recommendation_types.append(data['recommendation_type'])\n",
    "    open_to_relocate_for_work.append(data['open_to_relocate_for_work'])\n",
    "    work_type_preferences.append(data['work_type_preference'])\n",
    "    locations.append(data['location'])\n",
    "    years_of_experiences.append(data['years_of_experience'])\n",
    "    for domain in data['target_domains']:\n",
    "        target_domains.append(domain)\n",
    "    for domain in data['skills_domains']:\n",
    "        skills_domains.append(domain)\n",
    "\n",
    "type_counts = Counter(recommendation_types)\n",
    "print(\"\\nRecommendation Type Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "type_counts = Counter(open_to_relocate_for_work)\n",
    "print(\"\\nopen_to_relocate_for_work Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "type_counts = Counter(work_type_preferences)\n",
    "print(\"\\nWork type preferences Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "type_counts = Counter(years_of_experiences)\n",
    "print(\"\\nyears_of_experience Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "type_counts = Counter(locations)\n",
    "print(\"\\nLocation Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "type_counts = Counter(target_domains)\n",
    "print(\"\\ntarget_domains Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "type_counts = Counter(skills_domains)\n",
    "print(\"\\nskills_domains Counts:\")\n",
    "for type_name, count in type_counts.most_common():\n",
    "    print(f\"{type_name}: {count}\")\n",
    "print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "\"\"\"\n",
    "item_counts, value_counts = compute_stat_for_multi_items(persona_infos, 'skills', include_values=True)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nSkills Values Counts:\")\n",
    "print(f\"\\nTotal occurrences: {sum(value_counts.values())}\")\n",
    "print(f\"Total unique types: {len(value_counts)}\")\n",
    "for item, count in value_counts.most_common():\n",
    "    print(f\"{item}: {count}\")\n",
    "print(\"\\nSkills Counts:\")\n",
    "print(f\"\\nTotal occurrences: {sum(item_counts.values())}\")\n",
    "print(f\"Total unique types: {len(item_counts)}\")\n",
    "for item, count in item_counts.most_common():\n",
    "    print(f\"{item}: {count}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e873b4a4-1490-4871-ae58-9d13060138cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19224f59-4df5-460d-a775-5e335fb97d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¼ Testing Persona information Extraction Agent...\n",
      "Reading a sample job file...\n",
      "\n",
      "name='Camila' age=22 location='Fortaleza' recommendation_type='trainings_only' open_to_relocate_for_work=False work_type_preference='onsite' target_domains=['UNKNOWN'] education_level='TÃ©cnico' years_of_experience=0 skills_domains=['UNKNOWN'] skills={} languages={'Portuguese', 'English'} goals='Learn all basics of live event production: lights, sound, stage setup.'\n"
     ]
    }
   ],
   "source": [
    "# Correct Persona Info Extraction\n",
    "print(\"ðŸ’¼ Testing Persona information Extraction Agent...\")\n",
    "print(\"Reading a sample job file...\\n\")\n",
    "\n",
    "filename = f\"interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)\n",
    "\n",
    "filename = f\"personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "personas_data = read_json(personas_save_path)\n",
    "\n",
    "# Get first job file\n",
    "persona_id = \"persona_015\"\n",
    "\n",
    "if persona_id in interviews:\n",
    "    conversation = interviews[persona_id]\n",
    "\n",
    "    # Extract\n",
    "    persona_info = extract_persona_info(activities_domains, skills_domains, conversation)\n",
    "    personas_data[persona_id] = persona_info.model_dump_json()\n",
    "    save_json(personas_save_path, personas_data)\n",
    "\n",
    "    print(persona_info)\n",
    "    #persona_infos[persona_id] = persona_info.model_dump_json()\n",
    "    \n",
    "    # persona_info = extract_persona_info(activities_domains, skills_domains, conversation)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025f470-5693-451a-a5d3-08502b9162fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
