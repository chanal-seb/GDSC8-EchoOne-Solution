{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9c5792f-324c-4b3c-8375-c3539fe5dde0",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting strands-agents[mistral]\n",
      "  Downloading strands_agents-1.12.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.39)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.39)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents[mistral])\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mcp<2.0.0,>=1.11.0 (from strands-agents[mistral])\n",
      "  Downloading mcp-1.17.0-py3-none-any.whl.metadata (80 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_instrumentation_threading-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (6.0.0)\n",
      "Collecting mistralai>=1.8.2 (from strands-agents[mistral])\n",
      "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.5.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.11.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting httpx>=0.27.1 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.25.1)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.4.0 (from strands-agents[mistral])\n",
      "  Downloading pydantic-2.12.2-py3-none-any.whl.metadata (85 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.37.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral])\n",
      "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (1.17.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral])\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.7.0)\n",
      "Collecting pydantic-core==2.41.4 (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral])\n",
      "  Downloading pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral])\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.27.1)\n",
      "Collecting eval-type-backport>=0.2.0 (from mistralai>=1.8.2->strands-agents[mistral])\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting invoke<3.0.0,>=2.2.0 (from mistralai>=1.8.2->strands-agents[mistral])\n",
      "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (6.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (8.3.0)\n",
      "Downloading strands_agents-1.12.0-py3-none-any.whl (216 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading mcp-1.17.0-py3-none-any.whl (167 kB)\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_instrumentation_threading-0.59b0-py3-none-any.whl (9.3 kB)\n",
      "Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading pydantic-2.12.2-py3-none-any.whl (460 kB)\n",
      "Downloading pydantic_core-2.41.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
      "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, python-multipart, python-dotenv, pydantic-core, invoke, httpx-sse, httpcore, eval-type-backport, docstring-parser, pydantic, opentelemetry-api, sse-starlette, pydantic-settings, opentelemetry-semantic-conventions, httpx, opentelemetry-sdk, opentelemetry-instrumentation, mistralai, mcp, opentelemetry-instrumentation-threading, strands-agents\n",
      "\u001b[2K  Attempting uninstall: pydantic-core\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.23.4\n",
      "\u001b[2K    Uninstalling pydantic_core-2.23.4:\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.23.4\n",
      "\u001b[2K  Attempting uninstall: pydanticm\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [httpcore]\n",
      "\u001b[2K    Found existing installation: pydantic 2.9.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [httpcore]\n",
      "\u001b[2K    Uninstalling pydantic-2.9.2:0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [httpcore]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.9.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/21\u001b[0m [httpcore]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21/21\u001b[0m [strands-agents]m [strands-agents]strumentation]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "safety-schemas 0.0.14 requires pydantic<2.10.0,>=2.6.0, but you have pydantic 2.12.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed docstring-parser-0.17.0 eval-type-backport-0.2.2 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 invoke-2.2.1 mcp-1.17.0 mistralai-1.9.11 opentelemetry-api-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-threading-0.59b0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 pydantic-2.12.2 pydantic-core-2.41.4 pydantic-settings-2.11.0 python-dotenv-1.1.1 python-multipart-0.0.20 sse-starlette-3.0.2 strands-agents-1.12.0 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents[mistral] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e600f23a-ddd6-499b-9acc-a94310b92398",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key found, we're ready to roll\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "\n",
    "import pprint\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, TypeVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pydantic for structured data\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands for AI agents\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import (\n",
    "    save_json,\n",
    "    read_json,\n",
    "    load_file_content,\n",
    "    get_job_paths,\n",
    "    get_training_paths,\n",
    "    sanity_check,\n",
    "\tchat_with_persona,\n",
    "    track_api_call,  # Cost tracking from utils\n",
    "    print_cost_summary,  # Cost summary from utils\n",
    "    reset_cost_tracker  # Reset cost tracker from utils\n",
    ")\n",
    "\n",
    "from src.my_utils import (\n",
    "    display_markdown_file,\n",
    "    call_mistral,\n",
    "    get_agent,\n",
    "    batch_extract,\n",
    "    compute_stat_for_multi_items\n",
    ")\n",
    "\n",
    "from src.models.job_info import JobInfo\n",
    "from src.prompts.job_extraction_prompt import JOB_EXTRACTION_PROMPT\n",
    "\n",
    "# Load API key from .env file\n",
    "dotenv.load_dotenv(\"../env\")\n",
    "\n",
    "# Check if we're good to go\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"âŒ No MISTRAL_API_KEY found!\")\n",
    "    print(\"Create an env file with your API key\")\n",
    "else:\n",
    "    print(\"âœ… API key found, we're ready to roll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90ab9485-48ce-4650-b7e0-48883b9c5547",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job_data_version version: v4\n"
     ]
    }
   ],
   "source": [
    "with open(\"../src/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "job_data_version = config[\"job_data_version\"]\n",
    "print(f\"job_data_version version: {job_data_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fe04b3-d62e-467e-ace8-30be9c79bb8a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_JOBS_DIR = Path('../data_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29d5679-10c3-408d-89ef-b030433628c3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_job_info(\n",
    "    path: Path,\n",
    "    model: str = \"mistral-small-latest\"\n",
    ") -> JobInfo:\n",
    "    \"\"\"Extract job info from file using Job Extraction Agent\"\"\"\n",
    "    text = load_file_content(path)\n",
    "    prompt = JOB_EXTRACTION_PROMPT + text\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=JobInfo, prompt=prompt)\n",
    "    result.domains = []\n",
    "    result.required_skills = {}\n",
    "    result.required_skills_domains = []\n",
    "\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27a4f891-7b7a-44f3-8ff0-597d569629b6",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Processing Jobs...\n",
      "Processing 200 files (0 already cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|â–ˆâ–ˆâ–Œ       | 50/200 [01:09<03:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’° Cost update after 50 new items:\n",
      "ğŸ’° Cost Summary:\n",
      "  Total API calls: 0\n",
      "  Total tokens: 0\n",
      "  Estimated cost: $0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 100/200 [02:27<02:25,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’° Cost update after 100 new items:\n",
      "ğŸ’° Cost Summary:\n",
      "  Total API calls: 0\n",
      "  Total tokens: 0\n",
      "  Estimated cost: $0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 130/200 [03:14<01:56,  1.66s/it]/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
      "  PydanticSerializationUnexpectedValue(Expected `list[str]` - serialized value may not be as expected [field_name='required_skills_domains', input_value={}, input_type=dict])\n",
      "  return self.__pydantic_serializer__.to_python(\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 150/200 [03:44<01:29,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’° Cost update after 150 new items:\n",
      "ğŸ’° Cost Summary:\n",
      "  Total API calls: 0\n",
      "  Total tokens: 0\n",
      "  Estimated cost: $0.0000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [04:58<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’° Cost update after 200 new items:\n",
      "ğŸ’° Cost Summary:\n",
      "  Total API calls: 0\n",
      "  Total tokens: 0\n",
      "  Estimated cost: $0.0000\n",
      "\n",
      "\n",
      "âœ… Processed 200 new items\n",
      "ğŸ’° Cost Summary:\n",
      "  Total API calls: 0\n",
      "  Total tokens: 0\n",
      "  Estimated cost: $0.0000\n",
      "âœ… Extracted 200 jobs\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all jobs\n",
    "print(\"ğŸ“‚ Processing Jobs...\")\n",
    "\n",
    "filename = f\"extracted_jobs_{job_data_version}.json\"\n",
    "jobs_save_path = DATA_JOBS_DIR / filename\n",
    "\n",
    "jobs_data = batch_extract(\n",
    "    get_job_paths(),\n",
    "    extract_job_info,\n",
    "    jobs_save_path,\n",
    "    show_cost_every=50  # Show cost update every 50 items\n",
    ")\n",
    "\n",
    "# Convert to JobInfo objects\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(data)\n",
    "    for job_id, data in jobs_data.items()\n",
    "}\n",
    "\n",
    "print(f\"âœ… Extracted {len(jobs_info)} jobs\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3532188-c1b5-407a-ac9d-d47486993d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"extracted_jobs_{job_data_version}.json\"\n",
    "jobs_save_path = DATA_JOBS_DIR / filename\n",
    "jobs_data = read_json(jobs_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b572b5f9-25e7-415b-a634-b0ffae52412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_job_data_stastistics(jobs_data):\n",
    "    # Extract infos from the dictionary\n",
    "    work_types = []\n",
    "    education_level_requireds = []\n",
    "    years_of_experience_requireds = []\n",
    "    for job_data in jobs_data.values():\n",
    "        data = json.loads(job_data)\n",
    "        work_types.append(data['work_type'])\n",
    "        education_level_requireds.append(data['education_level_required'])\n",
    "        years_of_experience_requireds.append(data['years_of_experience_required'])\n",
    "\n",
    "    type_counts = Counter(work_types)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\nwork_types Counts:\")\n",
    "    for type_name, count in type_counts.most_common():\n",
    "        print(f\"{type_name}: {count}\")\n",
    "    print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "    type_counts = Counter(education_level_requireds)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\neducation_level_requireds Counts:\")\n",
    "    for type_name, count in type_counts.most_common():\n",
    "        print(f\"{type_name}: {count}\")\n",
    "    print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "    type_counts = Counter(years_of_experience_requireds)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\nyears_of_experience_requireds Counts:\")\n",
    "    for type_name, count in type_counts.most_common():\n",
    "        print(f\"{type_name}: {count}\")\n",
    "    print(f\"\\nTotal count: {sum(type_counts.values())}\")\n",
    "\n",
    "    item_counts = compute_stat_for_multi_items(jobs_data, 'required_languages', include_values=False)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\nRequired Languages Counts:\")\n",
    "    print(f\"\\nTotal occurrences: {sum(item_counts.values())}\")\n",
    "    print(f\"Total unique languages: {len(item_counts)}\")\n",
    "    for item, count in item_counts.most_common():\n",
    "        print(f\"{item}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38548802-d25b-4297-9e3e-e79c03622fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\n",
      "work_types Counts:\n",
      "onsite: 158\n",
      "remote: 42\n",
      "\n",
      "Total count: 200\n",
      "\n",
      "==================================================\n",
      "\n",
      "education_level_requireds Counts:\n",
      "GraduaÃ§Ã£o: 81\n",
      "TÃ©cnico: 60\n",
      "TecnÃ³logo: 53\n",
      "Bacharelado: 6\n",
      "\n",
      "Total count: 200\n",
      "\n",
      "==================================================\n",
      "\n",
      "years_of_experience_requireds Counts:\n",
      "1: 61\n",
      "2: 59\n",
      "0: 46\n",
      "3: 34\n",
      "\n",
      "Total count: 200\n",
      "\n",
      "==================================================\n",
      "\n",
      "Required Languages Counts:\n",
      "\n",
      "Total occurrences: 254\n",
      "Total unique languages: 2\n",
      "Portuguese: 200\n",
      "English: 54\n"
     ]
    }
   ],
   "source": [
    "compute_job_data_stastistics(jobs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b852e70-f073-4164-88c5-7d28388f1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_json_content(file1_path: str, file2_path: str) -> dict:\n",
    "    # Read both JSON files\n",
    "    with open(file1_path, 'r') as f1:\n",
    "        data1 = json.load(f1)\n",
    "    with open(file2_path, 'r') as f2:\n",
    "        data2 = json.load(f2)\n",
    "    \n",
    "    differences = {}\n",
    "    \n",
    "    # Compare content for each key present in both files\n",
    "    common_keys = set(data1.keys()) & set(data2.keys())\n",
    "    \n",
    "    for key in sorted(common_keys):\n",
    "        job1 = json.loads(data1[key])  # Parse the JSON string content\n",
    "        job2 = json.loads(data2[key])  # Parse the JSON string content\n",
    "        \n",
    "        # Compare each field in the job listing\n",
    "        field_differences = {}\n",
    "        all_fields = set(job1.keys()) | set(job2.keys())\n",
    "        \n",
    "        for field in all_fields:\n",
    "            value1 = job1.get(field)\n",
    "            value2 = job2.get(field)\n",
    "            if value1 != value2:\n",
    "                field_differences[field] = {\n",
    "                    'file1': value1,\n",
    "                    'file2': value2\n",
    "                }\n",
    "        \n",
    "        # Only add to differences if there are actual differences\n",
    "        if field_differences:\n",
    "            differences[key] = field_differences\n",
    "    \n",
    "    return differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38eb0a-df15-40d3-a2ff-577d7198aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_differences(differences: dict) -> None:\n",
    "    if not differences:\n",
    "        print(\"No differences found in job contents between the files.\")\n",
    "        return\n",
    "        \n",
    "    print(f\"\\nFound differences in {len(differences)} jobs:\")\n",
    "    for job_key, job_diffs in differences.items():\n",
    "        print(f\"\\nJob {job_key}:\")\n",
    "        for field, values in job_diffs.items():\n",
    "            print(f\"  Field '{field}':\")\n",
    "            print(f\"    File 1: {values['file1']}\")\n",
    "            print(f\"    File 2: {values['file2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cafa7-3571-415e-8d9e-b054c3819913",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_path = DATA_JOBS_DIR / \"extracted_jobs_v2.json\"\n",
    "file2_path = DATA_JOBS_DIR / \"extracted_jobs_v3.json\"\n",
    "differences = compare_json_content(file1_path, file2_path)\n",
    "print_differences(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53ba40d-8a1a-4bc7-a1cc-398839d0551d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0dbaca-721c-486d-9ebe-09c795094135",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Job Extraction Agent\n",
    "print(\"ğŸ’¼ Testing Job Extraction Agent...\")\n",
    "print(\"Reading a sample job file...\\n\")\n",
    "\n",
    "# Get first job file\n",
    "job_paths = get_job_paths()\n",
    "if job_paths:\n",
    "    print(job_paths[0])\n",
    "    sample_job = extract_job_info(job_paths[0])\n",
    "    print(f\"Job ID: {job_paths[0].stem}\")\n",
    "    print(sample_job.describe())\n",
    "    print(\"\\nRaw Pydantic model:\")\n",
    "    print(sample_job.model_dump())\n",
    "else:\n",
    "    print(\"No job files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870f844-3bc2-45e3-a2a6-7f6bc98adb20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
