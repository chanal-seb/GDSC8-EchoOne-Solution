{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c5792f-324c-4b3c-8375-c3539fe5dde0",
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting strands-agents[mistral]\n",
      "  Downloading strands_agents-1.11.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.39)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.39)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents[mistral])\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting mcp<2.0.0,>=1.11.0 (from strands-agents[mistral])\n",
      "  Downloading mcp-1.16.0-py3-none-any.whl.metadata (80 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_api-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_instrumentation_threading-0.58b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (6.0.0)\n",
      "Collecting mistralai>=1.8.2 (from strands-agents[mistral])\n",
      "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.5.0)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.11.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading httpx_sse-0.4.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting httpx>=0.27.1 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.25.1)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting pydantic<3.0.0,>=2.4.0 (from strands-agents[mistral])\n",
      "  Downloading pydantic-2.12.0-py3-none-any.whl.metadata (83 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.37.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.58b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral])\n",
      "  Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (1.17.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.58b0 (from opentelemetry-instrumentation==0.58b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral])\n",
      "  Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.58b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.7.0)\n",
      "Collecting pydantic-core==2.41.1 (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral])\n",
      "  Downloading pydantic_core-2.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral])\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.16.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.27.1)\n",
      "Collecting eval-type-backport>=0.2.0 (from mistralai>=1.8.2->strands-agents[mistral])\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting invoke<3.0.0,>=2.2.0 (from mistralai>=1.8.2->strands-agents[mistral])\n",
      "  Downloading invoke-2.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (6.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (8.3.0)\n",
      "Downloading strands_agents-1.11.0-py3-none-any.whl (213 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading mcp-1.16.0-py3-none-any.whl (167 kB)\n",
      "Downloading opentelemetry_api-1.37.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_instrumentation_threading-0.58b0-py3-none-any.whl (9.3 kB)\n",
      "Downloading opentelemetry_instrumentation-0.58b0-py3-none-any.whl (33 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.58b0-py3-none-any.whl (207 kB)\n",
      "Downloading opentelemetry_sdk-1.37.0-py3-none-any.whl (131 kB)\n",
      "Downloading pydantic-2.12.0-py3-none-any.whl (459 kB)\n",
      "Downloading pydantic_core-2.41.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m123.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.2-py3-none-any.whl (9.0 kB)\n",
      "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
      "Downloading invoke-2.2.0-py3-none-any.whl (160 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, python-multipart, python-dotenv, pydantic-core, invoke, httpx-sse, httpcore, eval-type-backport, docstring-parser, pydantic, opentelemetry-api, sse-starlette, pydantic-settings, opentelemetry-semantic-conventions, httpx, opentelemetry-sdk, opentelemetry-instrumentation, mistralai, mcp, opentelemetry-instrumentation-threading, strands-agents\n",
      "\u001b[2K  Attempting uninstall: pydantic-core\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.23.4\n",
      "\u001b[2K    Uninstalling pydantic_core-2.23.4:\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.23.4\n",
      "\u001b[2K  Attempting uninstall: pydantic[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 5/21\u001b[0m [httpx-sse]ore]\n",
      "\u001b[2K    Found existing installation: pydantic 2.9.2‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 5/21\u001b[0m [httpx-sse]\n",
      "\u001b[2K    Uninstalling pydantic-2.9.2:0m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 9/21\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.9.2‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m 9/21\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21/21\u001b[0m [strands-agents]m [strands-agents]dk]onventions]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "safety-schemas 0.0.14 requires pydantic<2.10.0,>=2.6.0, but you have pydantic 2.12.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed docstring-parser-0.17.0 eval-type-backport-0.2.2 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.2 invoke-2.2.0 mcp-1.16.0 mistralai-1.9.11 opentelemetry-api-1.37.0 opentelemetry-instrumentation-0.58b0 opentelemetry-instrumentation-threading-0.58b0 opentelemetry-sdk-1.37.0 opentelemetry-semantic-conventions-0.58b0 pydantic-2.12.0 pydantic-core-2.41.1 pydantic-settings-2.11.0 python-dotenv-1.1.1 python-multipart-0.0.20 sse-starlette-3.0.2 strands-agents-1.11.0 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents[mistral] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e600f23a-ddd6-499b-9acc-a94310b92398",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API key found, we're ready to roll\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import html\n",
    "\n",
    "import pprint\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path, PosixPath\n",
    "from typing import Dict, List, Tuple, TypeVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pydantic for structured data\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands for AI agents\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import (\n",
    "    save_json,\n",
    "    read_json,\n",
    "    load_file_content,\n",
    "    get_job_paths,\n",
    "    get_training_paths,\n",
    "    sanity_check,\n",
    "\tchat_with_persona,\n",
    "    track_api_call,  # Cost tracking from utils\n",
    "    print_cost_summary,  # Cost summary from utils\n",
    "    reset_cost_tracker  # Reset cost tracker from utils\n",
    ")\n",
    "\n",
    "from src.my_utils import (\n",
    "    display_markdown_file,\n",
    "    call_mistral,\n",
    "    get_agent,\n",
    "    batch_extract,\n",
    "    compute_stat_for_multi_items\n",
    ")\n",
    "\n",
    "from src.models.activity_domain_info import ActivityDomainInfo\n",
    "from src.models.training_info import TrainingInfo\n",
    "from src.models.job_info import JobInfo, JobInfoRequiredSkills\n",
    "\n",
    "from src.prompts.job_extraction_prompt import (\n",
    "    FIND_TRAINING_MATCHES_PROMPT\n",
    ")\n",
    "\n",
    "from src.models.generic_models import (\n",
    "    ListOfIds\n",
    ")\n",
    "\n",
    "# Load API key from .env file\n",
    "dotenv.load_dotenv(\"../env\")\n",
    "\n",
    "# Check if we're good to go\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"‚ùå No MISTRAL_API_KEY found!\")\n",
    "    print(\"Create an env file with your API key\")\n",
    "else:\n",
    "    print(\"‚úÖ API key found, we're ready to roll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c2790b2-ab21-4a0c-8f52-58c43bf55815",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PERSONAS_INFO_DIR = Path('../data_personas_info')\n",
    "DATA_JOBS_DIR = Path('../data_jobs')\n",
    "DATA_TRAININGS_DIR = Path('../data_trainings')\n",
    "DATA_SKILLS_DOMAINS_DIR = Path('../data_skills_domains')\n",
    "DATA_MATCH_JOBS_TRAININGS_DIR = Path('../data_match_jobs_trainings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b526e0c-9f50-40cf-8a82-5af61ddfcc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas_info_data_version version: v10\n",
      "job_data_version version: v4\n",
      "training_data_version version: v7\n",
      "skill_domains_version version: v3\n"
     ]
    }
   ],
   "source": [
    "with open(\"../src/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "personas_info_data_version = config[\"personas_info_data_version\"]\n",
    "print(f\"personas_info_data_version version: {personas_info_data_version}\")\n",
    "\n",
    "job_data_version = config[\"job_data_version\"]\n",
    "print(f\"job_data_version version: {job_data_version}\")\n",
    "\n",
    "training_data_version = config[\"training_data_version\"]\n",
    "print(f\"training_data_version version: {training_data_version}\")\n",
    "\n",
    "skill_domains_version = config[\"skill_domains_version\"]\n",
    "print(f\"skill_domains_version version: {skill_domains_version}\")\n",
    "\n",
    "match_skills_domains_trainings_data_version = f\"{skill_domains_version}_{training_data_version}\"\n",
    "match_jobs_trainings_data_version = f\"{job_data_version}_{training_data_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1379b985-f52f-46b6-9d7a-10d29af58425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 200 jobs\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load jobs data\n",
    "filename = f\"skill_domain_classified_jobs_{job_data_version}.json\"\n",
    "jobs_save_path = DATA_JOBS_DIR / filename\n",
    "jobs_data = read_json(jobs_save_path)\n",
    "\n",
    "# Convert to JobInfo objects\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(data)\n",
    "    for job_id, data in jobs_data.items()\n",
    "}\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(jobs_info)} jobs\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effd06d3-d7d1-43e9-98aa-bc23e34eb76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 28400.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load job descriptions\n",
    "job_descriptions = {}\n",
    "job_paths = get_job_paths()\n",
    "for path in tqdm(job_paths):\n",
    "    id_ = path.stem\n",
    "    text = load_file_content(path)\n",
    "    job_descriptions[id_]=text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc797fcc-4809-4ebb-b13d-552e276f13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 12 skills domains\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load skills domains data\n",
    "filename = f\"final_map_clusters_trainings_{training_data_version}.json\"\n",
    "save_path = DATA_TRAININGS_DIR / filename\n",
    "trainings_map = read_json(save_path)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(trainings_map)} skills domains\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c62ff6d-c749-4b89-b8c9-24a2f7aee3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_match_jobs_training(\n",
    "    job_description,\n",
    "    trainings_list,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt=False\n",
    ") -> JobInfoRequiredSkills:\n",
    "\n",
    "    prompt = FIND_TRAINING_MATCHES_PROMPT.format(\n",
    "        job_description=\"-----------\\n\" + job_description + \"\\n-----------\",\n",
    "        formatted_skills=trainings_list\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "\n",
    "    # return None\n",
    "    \n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=JobInfoRequiredSkills, prompt=prompt)\n",
    "\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9110ec8f-60f1-4498-aee9-e15f4cd9b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    job_id = 'j1'\n",
    "    \n",
    "    training_ids = []\n",
    "    for required_skills_domain in jobs_info[job_id].required_skills_domains:\n",
    "        training_ids.extend(skill_domain_training_map[required_skills_domain])\n",
    "    \n",
    "    skills_str = \"\"\n",
    "    for training_id in training_ids:\n",
    "        skills_str += trainings_info[training_id].get_skill_acquired(training_id) + \"\\n\"\n",
    "    \n",
    "    selected_trainings = extend_match_jobs_training(jobs_info[job_id].get_required_skills(), skills_str, print_prompt=True)\n",
    "    print(selected_trainings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836ca49b-d043-408e-9432-81bf0fee92eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Processing Jobs...\n",
      "START CLASSIFICATION LOOP\n",
      "ITERATE CLASSIFICATION LOOP\n",
      "Number of jobs not classisfied : 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an expert in skill taxonomy, training analysis, and job description interpretation.\n",
      "\n",
      "Your task is to identify which skill ‚Äîamong a predefined list‚Äîcover the skills required for the job described below.\n",
      "\n",
      "# Job Description:\n",
      "-----------\n",
      "# Job Description: Accounting Intern ‚Äì Bookkeeping & Admin\n",
      "\n",
      "**Position Summary:**\n",
      "As an **Accounting Intern ‚Äì Bookkeeping & Admin** on our **Accounting and Management** team, you'll handle day-to-day financial record keeping and administrative tasks that keep our operations running smoothly.\n",
      "\n",
      "**Your Responsibilities:**\n",
      "Your main tasks will include maintaining accurate financial records and transaction entries, managing tax-related documentation and compliance requirements, and supporting general administrative functions across the accounting department. You'll work closely with senior accounting staff and other departments that need financial data and reporting.\n",
      "\n",
      "**What We're Looking For:**\n",
      "You should have solid experience with **tax regulations and compliance processes at an intermediate level**, along with strong attention to detail and organizational skills. We expect a background of **graduation-level education and around 2 years of relevant experience**. You'll need to be fluent in **Portuguese (Brazilian)** and **English** to handle our documentation and communications effectively.\n",
      "\n",
      "**Location:**\n",
      "This position is based in **Bras√≠lia** and requires in-person work to access our financial systems and collaborate with the team.\n",
      "\n",
      "**How to Apply:**\n",
      "If you think you're a good fit, please send your application with your resume and a brief cover letter explaining your interest in this accounting internship role.\n",
      "-----------\n",
      "\n",
      "# Existing Skills:\n",
      "- Financial Risk Management And Compliance / Financial Software Proficiency\n",
      "- Financial Risk Management And Compliance / Cost Analysis And Financial Evaluation\n",
      "- Financial Risk Management And Compliance / Financial Data Analysis\n",
      "- Financial Risk Management And Compliance / Financial Compliance Reporting\n",
      "- Financial Risk Management And Compliance / Corporate Financial Reporting\n",
      "- Financial Risk Management And Compliance / Regulatory Compliance Management\n",
      "- Financial Risk Management And Compliance / Actuarial Science\n",
      "- Financial Risk Management And Compliance / Insurance Claims Processing\n",
      "- Financial Risk Management And Compliance / Insurance Legal Agreements Interpretation\n",
      "- Financial Risk Management And Compliance / Business Risk Management\n",
      "- Financial Risk Management And Compliance / Intermediate Client Interaction And Problem Resolution\n",
      "- Financial Risk Management And Compliance / Insurance Pricing Analytics\n",
      "- Financial Risk Management And Compliance / Fraud Detection And Prevention\n",
      "- Financial Risk Management And Compliance / Risk Assessment\n",
      "- Financial Risk Management And Compliance / Insurance Risk Assessment And Decision Making\n",
      "- Financial Risk Management And Compliance / Insurance Sales And Marketing\n",
      "- Financial Risk Management And Compliance / Strategic Planning And Analysis\n",
      "- Financial Risk Management And Compliance / Tax Regulation And Compliance\n",
      "- Financial Risk Management And Compliance / Financial Auditing\n",
      "- Financial Risk Management And Compliance / Customer Information Systems Management\n",
      "- Financial Risk Management And Compliance / Regulatory Supervision\n",
      "- Financial Risk Management And Compliance / Financial Data Security\n",
      "- Financial Risk Management And Compliance / Document Management\n",
      "- Financial Risk Management And Compliance / Financial Crime Prevention And Detection\n",
      "- Financial Risk Management And Compliance / Cross-Functional Coordination And Communication\n",
      "- Financial Risk Management And Compliance / Process Optimization In Financial Services\n",
      "- Financial Risk Management And Compliance / Organizational Policy Implementation\n",
      "- Financial Risk Management And Compliance / Risk Documentation Management\n",
      "- Financial Risk Management And Compliance / Financial Planning And Budgeting\n",
      "\n",
      "\n",
      "# Instructions:\n",
      "- Carefully read the job description and compare it to the list of existing skills.\n",
      "- If the job clearly mentions skills that align with one or more skills, respond with a list of skills with their required proficiency levels (Basic, Intermediate, or Advanced)\n",
      "- If none of the skills match the job description, respond with an empty list:\n",
      "   []\n",
      "- Be conservative:\n",
      "    - select only skills that clearly mentioned in the job description.\n",
      "    - do not derived needed skills from vague competence description. (Hint: if no proficency level is defined(Basic, Intermediate, or Advanced), consider it is vague)\n",
      "- Do NOT modify, rename, or create new skills.\n",
      "- IMPORTANT:\n",
      "   - You MUST use only the skills listed in 'Existing Skill Domains'.\n",
      "   - NEVER infer or reuse skill names from the job description if they are not in the provided list (but select closer in the list).\n",
      "   - If no match is found, return an empty list.\n",
      "\n",
      "Respond with foowing fields :\n",
      "- Required skills: Dictionary of skills with their required proficiency levels (Basic, Intermediate, or Advanced)\n",
      "- rationale: Justification of the decision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 9/200 [00:56<26:21,  8.28s/it]"
     ]
    }
   ],
   "source": [
    "MAX_LOOPS = 1\n",
    "cache_period = 5\n",
    "\n",
    "# Process all jobs\n",
    "print(\"üìÇ Processing Jobs...\")\n",
    "\n",
    "filename = f\"match_jobs_trainings_{match_jobs_trainings_data_version}.json\"\n",
    "save_path = DATA_MATCH_JOBS_TRAININGS_DIR / filename\n",
    "if not save_path.exists():\n",
    "    save_json(save_path, {})\n",
    "job_training_map = read_json(save_path)\n",
    "\n",
    "new_items_processed = 0\n",
    "\n",
    "print(\"START CLASSIFICATION LOOP\")\n",
    "for i in range(MAX_LOOPS):\n",
    "    print(\"ITERATE CLASSIFICATION LOOP\")\n",
    "\n",
    "    filt_jobs_ids = []\n",
    "    for job_id in jobs_info:\n",
    "        # print(jobs_info)\n",
    "        if job_id not in job_training_map:\n",
    "            filt_jobs_ids.append(job_id)\n",
    "            continue\n",
    "\n",
    "        # trainings_list = job_training_map[job_id]\n",
    "\n",
    "        # if len(trainings_list) == 0:\n",
    "        #     filt_jobs_ids.append(job_id)\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     for training_id in trainings_list:\n",
    "        #         if training_id not in trainings_data:\n",
    "        #             # print(f\"Training id error : {training_id}\")\n",
    "        #             filt_jobs_ids.append(job_id)\n",
    "        #             break\n",
    "\n",
    "    print(f\"Number of jobs not classisfied : {len(filt_jobs_ids)}\")\n",
    "\n",
    "    if len(filt_jobs_ids) == 0:\n",
    "        break\n",
    "\n",
    "    for job_id in tqdm(filt_jobs_ids):\n",
    "        new_items_processed = new_items_processed + 1\n",
    "\n",
    "        print_prompt = False\n",
    "        if new_items_processed == 1:\n",
    "            print_prompt = True\n",
    "        \n",
    "        job_info = jobs_info[job_id]\n",
    "\n",
    "        # print(job_info)\n",
    "        skills_str = \"\"\n",
    "        for domain in job_info.required_skills_domains:\n",
    "            if domain in trainings_map:\n",
    "                for skill in trainings_map[domain]:\n",
    "                    skills_str += \"- \" + domain + \" / \" + skill + \"\\n\"\n",
    "            else:\n",
    "                print(f\"ERROR : skill domain ({domain}) not referenced in skill domain training map for job {job_id}\")\n",
    "                        \n",
    "        result = extend_match_jobs_training(\n",
    "            job_descriptions[job_id],\n",
    "            skills_str,\n",
    "            model = \"mistral-medium-latest\",\n",
    "            print_prompt=print_prompt\n",
    "        )\n",
    "\n",
    "        # print(result)\n",
    "\n",
    "        job_training_map[job_id] = result.required_skills\n",
    "\n",
    "        if new_items_processed % cache_period == 0:\n",
    "            save_json(save_path, job_training_map)\n",
    "            \n",
    "        # print(job_training_map[job_id])\n",
    "        \n",
    "        # if new_items_processed > 0:break\n",
    "\n",
    "# Save results\n",
    "save_json(save_path, job_training_map)\n",
    "\n",
    "print(f\"\\n‚úÖ Generated matching for {len(job_training_map)} jobs\")\n",
    "print(f\"üìÅ Results saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6f760-13cc-48e8-b19c-9656c8089a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a46f4-c19c-4ce9-80ea-d423d4440ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
