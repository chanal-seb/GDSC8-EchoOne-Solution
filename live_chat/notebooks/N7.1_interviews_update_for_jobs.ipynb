{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec679c32-2ad8-4b65-8589-0dc11bb76c1c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting strands-agents[mistral]\n",
      "  Downloading strands_agents-1.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.52)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.29.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (1.40.52)\n",
      "Collecting docstring-parser<1.0,>=0.15 (from strands-agents[mistral])\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (4.25.1)\n",
      "Collecting mcp<2.0.0,>=1.11.0 (from strands-agents[mistral])\n",
      "  Downloading mcp-1.19.0-py3-none-any.whl.metadata (85 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.30.0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-instrumentation-threading<1.00b0,>=0.51b0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_instrumentation_threading-0.59b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.30.0 (from strands-agents[mistral])\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.13.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (4.15.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from strands-agents[mistral]) (6.0.0)\n",
      "Collecting mistralai>=1.8.2 (from strands-agents[mistral])\n",
      "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.15.0,>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0.0,>=1.26.0->strands-agents[mistral]) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (2.5.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents[mistral]) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents[mistral]) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents[mistral]) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->strands-agents[mistral]) (0.27.1)\n",
      "Requirement already satisfied: anyio>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (4.11.0)\n",
      "Collecting httpx-sse>=0.4 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting httpx>=0.27.1 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic-settings>=2.5.2 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting python-multipart>=0.0.9 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting sse-starlette>=1.6.1 (from mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Downloading sse_starlette-3.0.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: starlette>=0.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.48.0)\n",
      "Requirement already satisfied: uvicorn>=0.31.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.37.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (6.11.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.30.0->strands-agents[mistral]) (3.23.0)\n",
      "Collecting opentelemetry-instrumentation==0.59b0 (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral])\n",
      "  Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (1.17.3)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral])\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.59b0->opentelemetry-instrumentation-threading<1.00b0,>=0.51b0->strands-agents[mistral]) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (2.41.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.4.0->strands-agents[mistral]) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.29.0->strands-agents[mistral]) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio>=4.5->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (2025.10.5)\n",
      "Collecting httpcore==1.* (from httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral])\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (0.16.0)\n",
      "Collecting eval-type-backport>=0.2.0 (from mistralai>=1.8.2->strands-agents[mistral])\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting invoke<3.0.0,>=2.2.0 (from mistralai>=1.8.2->strands-agents[mistral])\n",
      "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from mistralai>=1.8.2->strands-agents[mistral]) (6.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from uvicorn>=0.31.1->mcp<2.0.0,>=1.11.0->strands-agents[mistral]) (8.3.0)\n",
      "Downloading strands_agents-1.14.0-py3-none-any.whl (238 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading mcp-1.19.0-py3-none-any.whl (170 kB)\n",
      "Downloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_instrumentation_threading-0.59b0-py3-none-any.whl (9.3 kB)\n",
      "Downloading opentelemetry_instrumentation-0.59b0-py3-none-any.whl (33 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
      "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading sse_starlette-3.0.2-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: python-multipart, python-dotenv, invoke, httpx-sse, httpcore, eval-type-backport, docstring-parser, opentelemetry-api, sse-starlette, pydantic-settings, opentelemetry-semantic-conventions, httpx, opentelemetry-sdk, opentelemetry-instrumentation, mistralai, mcp, opentelemetry-instrumentation-threading, strands-agents\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/18\u001b[0m [strands-agents]m [strands-agents]dk]onventions]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed docstring-parser-0.17.0 eval-type-backport-0.2.2 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.3 invoke-2.2.1 mcp-1.19.0 mistralai-1.9.11 opentelemetry-api-1.38.0 opentelemetry-instrumentation-0.59b0 opentelemetry-instrumentation-threading-0.59b0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 pydantic-settings-2.11.0 python-dotenv-1.2.1 python-multipart-0.0.20 sse-starlette-3.0.2 strands-agents-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install strands-agents[mistral] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bfd972d-da65-48b0-80de-278955331415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API key found, we're ready to roll\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "import boto3\n",
    "import requests\n",
    "\n",
    "import pprint\n",
    "\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, TypeVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Pydantic for structured data\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands for AI agents\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "# AWS authentication\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.utils import (\n",
    "    save_json,\n",
    "    read_json,\n",
    "    load_file_content,\n",
    "    get_job_paths,\n",
    "    get_training_paths,\n",
    "    sanity_check,\n",
    "\tchat_with_persona,\n",
    "    track_api_call,  # Cost tracking from utils\n",
    "    print_cost_summary,  # Cost summary from utils\n",
    "    reset_cost_tracker  # Reset cost tracker from utils\n",
    ")\n",
    "\n",
    "from src.my_utils import (\n",
    "    display_markdown_file,\n",
    "    call_mistral,\n",
    "    get_agent,\n",
    "    batch_extract,\n",
    "    send_message_to_chat\n",
    ")\n",
    "\n",
    "from src.models.interview_info import(\n",
    "    InterviewInfo,\n",
    "    InverviewQualityInfo,\n",
    "    InterviewAgentMessage\n",
    ")\n",
    "from src.prompts.interview_prompt import(\n",
    "    JOB_ROUND_INTERVIEW_PROMPT,\n",
    "    JOB_FEEDBACK_INTERVIEW_QUALITY_CHECK_PROMPT\n",
    ")\n",
    "\n",
    "from src.models.persona_info import PersonaInfo\n",
    "from src.models.job_info import JobInfo\n",
    "\n",
    "# Load API key from .env file\n",
    "dotenv.load_dotenv(\"../env\")\n",
    "\n",
    "# Check if we're good to go\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"❌ No MISTRAL_API_KEY found!\")\n",
    "    print(\"Create an env file with your API key\")\n",
    "else:\n",
    "    print(\"✅ API key found, we're ready to roll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8552d20-7d4e-415f-b967-ea120c30c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TURNS_IN_INTERVIEW = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f6e9d9-3e72-463e-b8ab-791e4256e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PERSONAS_INFO_DIR = Path('../data_personas_info')\n",
    "DATA_JOBS_DIR = Path('../data_jobs')\n",
    "DATA_TRAININGS_DIR = Path('../data_trainings')\n",
    "DATA_INTERVIEWS_DIR = Path('../data_interviews')\n",
    "DATA_MATCH_JOBS_TRAININGS_DIR = Path('../data_match_jobs_trainings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48c9ea1f-dac7-40bc-a92b-1e03617d9d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "personas_info_data_version version: v14\n",
      "job_data_version version: v4\n",
      "training_data_version version: v7\n",
      "interview_data_version version: v8\n"
     ]
    }
   ],
   "source": [
    "with open(\"../src/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "personas_info_data_version = config[\"personas_info_data_version\"]\n",
    "print(f\"personas_info_data_version version: {personas_info_data_version}\")\n",
    "\n",
    "job_data_version = config[\"job_data_version\"]\n",
    "print(f\"job_data_version version: {job_data_version}\")\n",
    "\n",
    "training_data_version = config[\"training_data_version\"]\n",
    "print(f\"training_data_version version: {training_data_version}\")\n",
    "\n",
    "interview_data_version = config[\"interview_data_version\"]\n",
    "print(f\"interview_data_version version: {interview_data_version}\")\n",
    "\n",
    "match_jobs_trainings_data_version = f\"{job_data_version}_{training_data_version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1c421a9-aadf-4854-86b2-1970e7243497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 100 personas\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load Personas data\n",
    "filename = f\"job_filtered_personas_info_{personas_info_data_version}.json\"\n",
    "personas_save_path = DATA_PERSONAS_INFO_DIR / filename\n",
    "\n",
    "personas_data = read_json(personas_save_path)\n",
    "\n",
    "# Convert to PersonaInfo objects\n",
    "personas = {\n",
    "    pid: PersonaInfo.model_validate_json(data)\n",
    "    for pid, data in personas_data.items()\n",
    "}\n",
    "\n",
    "print(f\"✅ Loaded {len(personas)} personas\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8542e60-3383-4818-915f-9b032e30618d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 200 jobs\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Load Jobs data\n",
    "filename = f\"final_jobs_{job_data_version}.json\"\n",
    "#filename = f\"final_jobs_{job_data_version}.json\"\n",
    "jobs_save_path = DATA_JOBS_DIR / filename\n",
    "\n",
    "jobs_data = read_json(jobs_save_path)\n",
    "\n",
    "# Convert to JobInfo objects\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(data)\n",
    "    for job_id, data in jobs_data.items()\n",
    "}\n",
    "\n",
    "print(f\"✅ Loaded {len(jobs_info)} jobs\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "072e7f8b-3674-49e9-b4c6-2d9f10f4cea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Match jobs trainings data\n",
    "filename = f\"match_jobs_trainings_{match_jobs_trainings_data_version}.json\"\n",
    "save_path = DATA_MATCH_JOBS_TRAININGS_DIR / filename\n",
    "jobs_trainings_map = read_json(save_path)\n",
    "\n",
    "# print(jobs_trainings_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e39c0c9-b243-4e0e-b87c-16f0cd66ed8d",
   "metadata": {},
   "source": [
    "# Prepare interview agent prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7301901d-a691-4399-8852-5e6e47882bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona_041 has no proposed_job_ids\n",
      "persona_069 has no proposed_job_ids\n",
      "persona_077 has no proposed_job_ids\n",
      "persona_079 has no proposed_job_ids\n"
     ]
    }
   ],
   "source": [
    "# from src.prompts.interview_prompt import(\n",
    "#     JOB_FEEDBACK_INTERVIEW_PROMPT_FOR_NO_JOB_INTEREST\n",
    "# )\n",
    "\n",
    "new_personas_processed = 0\n",
    "\n",
    "job_interview_round_prompt = {}\n",
    "\n",
    "for person_id in personas:\n",
    "    persona = personas[person_id]\n",
    "    persona_data = json.loads(personas_data[person_id])\n",
    "    if persona.recommendation_type == \"awareness\":\n",
    "        continue\n",
    "    if persona.recommendation_type == \"trainings_only\":\n",
    "        continue\n",
    "    if persona.recommendation_type == \"jobs_trainings\":\n",
    "        new_personas_processed += 1\n",
    "        if len(persona.proposed_job_ids) > 0:\n",
    "            job_list_str = \"\"\n",
    "            for job_id in persona.proposed_job_ids:\n",
    "                job_info = jobs_info[job_id]\n",
    "                job_list_str += f\"----- JOB {job_id} ------\" + \"\\n\"\n",
    "                job_list_str += job_info.describe_for_interview()\n",
    "                job_list_str += f\"Required skills :\" + \"\\n\"\n",
    "                for training in jobs_trainings_map[job_id]:\n",
    "                    job_list_str += \"- \" + training + \"\\n\"\n",
    "                job_list_str += \"\\n\"\n",
    "                job_interview_round_prompt[person_id] = job_list_str\n",
    "        else:\n",
    "            print(f\"{person_id} has no proposed_job_ids\")\n",
    "            job_list_str = \"NO JOBS FOUND\"\n",
    "            job_interview_round_prompt[person_id] = job_list_str\n",
    "            \n",
    "\n",
    "filename = f\"job_interview_round_prompt{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "save_json(save_path, job_interview_round_prompt)\n",
    "\n",
    "#print(job_interview_round_prompt['persona_010'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6c29c-70d4-4f4e-acce-42ccfc861cf7",
   "metadata": {},
   "source": [
    "# Perform interviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77e39d4-8740-4770-8afb-c442e70e2ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_job_round_persona_interview(\n",
    "    persona_id: str,\n",
    "    prompt_information: str,\n",
    "    conversation_id: str = None,\n",
    "    max_turns: int = 5,\n",
    "    model: str = \"mistral-medium-latest\",\n",
    "    print_conversation: bool = False\n",
    ") -> InterviewInfo:\n",
    "    \"\"\"Interview a persona and return conversation transcript\"\"\"\n",
    "\n",
    "    interview_info = InterviewInfo()\n",
    "    \n",
    "    conversation = []\n",
    "\n",
    "    prompt = JOB_ROUND_INTERVIEW_PROMPT\n",
    "\n",
    "    # print(prompt)\n",
    "    \n",
    "    # return []\n",
    "    \n",
    "    interview_agent = get_agent(prompt, model_id=model)\n",
    "\n",
    "    # Start with greeting\n",
    "    agent_message = \"Hello, I'm coming back to you regarding your career path.\\n\"\n",
    "    agent_message += \"Here is the list of jobs I have selected for you :\\n\"\n",
    "    agent_message += prompt_information\n",
    "\n",
    "    if print_conversation:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Assistant: {agent_message}\")\n",
    "        \n",
    "    conversation.append(f\"Assistant: {agent_message}\")\n",
    "              \n",
    "    # Conduct interview\n",
    "    for turn in range(max_turns):\n",
    "        resp = send_message_to_chat(agent_message, persona_id, conversation_id)\n",
    "\n",
    "        if resp is None:\n",
    "            break\n",
    "\n",
    "        user_response, conversation_id = resp\n",
    "        conversation.append(f\"User: {user_response}\")\n",
    "        if print_conversation:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"User: {user_response}\")\n",
    "            \n",
    "        # Generate next question\n",
    "        conversation_str = '\\n'.join(conversation)\n",
    "        # agent_response = interview_agent(user_response)\n",
    "        agent_response = interview_agent.structured_output(output_model=InterviewAgentMessage, prompt=conversation_str)\n",
    "\n",
    "        if agent_response.conversation_finished is True:\n",
    "            break\n",
    "\n",
    "        agent_message = agent_response.message\n",
    "        conversation.append(f\"Assistant: {agent_message}\")\n",
    "        if print_conversation:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    interview_info.conversation_id = conversation_id\n",
    "    interview_info.interview = conversation\n",
    "    \n",
    "    return interview_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf3d1d-4a70-479f-9f33-b89c5b87cfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"job_interview_round_prompt{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "job_interview_round_prompt = read_json(save_path)\n",
    "\n",
    "filename = f\"jobs_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "if not interviews_save_path.exists():\n",
    "    save_json(interviews_save_path, {})\n",
    "interviews = read_json(interviews_save_path)\n",
    "\n",
    "print(f'Personas to process: {len(job_interview_round_prompt)}')\n",
    "\n",
    "for persona_id in tqdm(job_interview_round_prompt):\n",
    "    #print(persona_id)\n",
    "    if persona_id not in interviews:\n",
    "        #print(persona_id)\n",
    "        interview_info = conduct_job_round_persona_interview(\n",
    "            persona_id,\n",
    "            job_interview_round_prompt[persona_id],\n",
    "            max_turns = 5,\n",
    "            model = \"mistral-medium-latest\",\n",
    "            print_conversation = True\n",
    "        )\n",
    "        #print(interview_info)\n",
    "        interviews[persona_id] = interview_info.model_dump()\n",
    "\n",
    "        save_json(interviews_save_path, interviews)\n",
    "        #break\n",
    "\n",
    "save_json(interviews_save_path, interviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc7879-3229-4096-aafd-6f40ad47e265",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# For Debug Only\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2dd4d4-e8c2-463c-a800-794c1af0ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    persona_id = 'persona_003'\n",
    "    interview_info = conduct_job_round_persona_interview(\n",
    "        persona_id,\n",
    "        job_interview_round_prompt[persona_id],\n",
    "        max_turns = 5,\n",
    "        model = \"mistral-medium-latest\",\n",
    "        print_conversation = True\n",
    "    )\n",
    "    \n",
    "    print(interview_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12352c54-add7-4781-b3b2-ced6aa574d34",
   "metadata": {},
   "source": [
    "# Redo Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d352c002-8782-4bff-8573-9664b32034b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39eba84b-46b0-4bc7-b29c-ceae08d4d602#persona_001#2025-10-30T20:14:10\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'persona_001'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     15\u001b[0m conversation_id \u001b[38;5;241m=\u001b[39m interview[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversation_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(conversation_id)\n\u001b[1;32m     18\u001b[0m interview_info \u001b[38;5;241m=\u001b[39m conduct_job_round_persona_interview(\n\u001b[1;32m     19\u001b[0m     persona_id,\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mjob_interview_round_prompt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpersona_id\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     21\u001b[0m     conversation_id\u001b[38;5;241m=\u001b[39mconversation_id,\n\u001b[1;32m     22\u001b[0m     max_turns\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral-medium-latest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     print_conversation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     27\u001b[0m new_interview \u001b[38;5;241m=\u001b[39m interview_info\u001b[38;5;241m.\u001b[39mmodel_dump()\n\u001b[1;32m     28\u001b[0m interview[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mextend(new_interview[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterview\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'persona_001'"
     ]
    }
   ],
   "source": [
    "persona_id = 'persona_001'\n",
    "\n",
    "filename = f\"job_interview_round_prompt{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "job_interview_round_prompt = read_json(save_path)\n",
    "\n",
    "#filename = f\"jobs_interviews_{interview_data_version}.json\"\n",
    "#interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "#interviews = read_json(interviews_save_path)\n",
    "\n",
    "filename = f\"full_interviews_{persona_id}.json\"\n",
    "interview_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interview = read_json(interview_save_path)\n",
    "\n",
    "conversation_id = interview['conversation_id']\n",
    "print(conversation_id)\n",
    "\n",
    "interview_info = conduct_job_round_persona_interview(\n",
    "    persona_id,\n",
    "    job_interview_round_prompt[persona_id],\n",
    "    conversation_id=conversation_id,\n",
    "    max_turns=10,\n",
    "    model=\"mistral-medium-latest\",\n",
    "    print_conversation=True\n",
    ")\n",
    "\n",
    "new_interview = interview_info.model_dump()\n",
    "interview['interview'].extend(new_interview['interview'])\n",
    "save_json(interview_save_path, interview)\n",
    "\n",
    "\n",
    "# print(interview_info)\n",
    "#interviews[persona_id] = interview_info.model_dump()\n",
    "#save_json(interviews_save_path, interviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c2f02-4efe-49d9-a8ab-aaa98c956165",
   "metadata": {},
   "source": [
    "# Check interview qualities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79bba8d5-dd70-4e6a-94f8-f6da4ea35b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_interview_quality(\n",
    "    persona_id,\n",
    "    interview: str,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt: bool = False\n",
    ") -> InverviewQualityInfo:\n",
    "    prompt = JOB_FEEDBACK_INTERVIEW_QUALITY_CHECK_PROMPT.format(\n",
    "        jobs_description=job_interview_round_prompt[persona_id],\n",
    "        interview=interview\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=InverviewQualityInfo, prompt=prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4af3fda3-b3db-4e6f-b91a-21f41a2e2938",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"jobs_interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab4c0691-8a61-42d1-a93d-f57e390e6c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"job_interview_round_prompt{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "job_interview_round_prompt = read_json(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d4605ac-548f-4aed-b738-4b9e4425eeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:15<00:00,  1.32it/s]\n"
     ]
    }
   ],
   "source": [
    "cache_period = 5\n",
    "\n",
    "filename = f\"quality_job_feedback_interviews_{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "if not save_path.exists():\n",
    "    save_json(save_path, {})\n",
    "quality_interviews = read_json(save_path)\n",
    "\n",
    "new_items_processed = 0\n",
    "for persona_id in tqdm(personas_data):\n",
    "    persona_data_dict = json.loads(personas_data[persona_id])\n",
    "    if persona_data_dict['recommendation_type'] != 'jobs_trainings':\n",
    "        continue\n",
    "\n",
    "    if persona_id not in job_interview_round_prompt:\n",
    "        continue\n",
    "\n",
    "    if persona_id not in interviews:\n",
    "        quality_data={\n",
    "            'quality_level': 'NOK',\n",
    "            'rationale': 'interview missing'\n",
    "        }\n",
    "\n",
    "        quality = InverviewQualityInfo(**quality_data)\n",
    "        quality_str = json.dumps(quality.model_dump(), ensure_ascii=False)\n",
    "        quality_interviews[persona_id] = quality_str\n",
    "        save_json(save_path, quality_interviews)\n",
    "        continue\n",
    "\n",
    "    if persona_id in quality_interviews:\n",
    "        quality = json.loads(quality_interviews[persona_id])\n",
    "        if quality['quality_level'] == 'OK':\n",
    "            continue\n",
    "\n",
    "    new_items_processed = new_items_processed + 1\n",
    "\n",
    "    interview = interviews[persona_id]['interview']\n",
    "\n",
    "    interview_str = \"\\n\".join(interview)\n",
    "    # print(interview_str)\n",
    "\n",
    "    quality = check_interview_quality(persona_id, interview_str, print_prompt=False)\n",
    "    quality_str = json.dumps(quality.model_dump(), ensure_ascii=False)\n",
    "\n",
    "    quality_interviews[persona_id] = quality_str\n",
    "\n",
    "    if new_items_processed % cache_period == 0:\n",
    "        save_json(save_path, quality_interviews)\n",
    "\n",
    "    #if new_items_processed > 0:break\n",
    "\n",
    "save_json(save_path, quality_interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18214a4-3f18-4b27-a9ec-76bcbcceeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona_057\n",
      "The interview does not provide sufficient information to confirm the persona's interest or proficiency level for the proposed jobs. The user expresses doubts and lacks experience in the required skills, making it difficult to assess their suitability for the roles.\n",
      "---\n",
      "persona_058\n",
      "The interview lacks detailed information about the user's interest in the proposed jobs and does not fully assess the proficiency level of the persona regarding the required skills for the jobs. Additionally, the user expresses uncertainty about their skills and preferences, which makes it difficult to confirm their interest and proficiency accurately.\n",
      "---\n",
      "persona_066\n",
      "The interview lacks detailed information about the user's interest in the proposed jobs and does not fully assess the user's proficiency in all required skills for the jobs. Additionally, the user's responses are somewhat inconsistent and do not provide a clear picture of their qualifications and career goals.\n",
      "---\n",
      "persona_071\n",
      "The interview lacks sufficient information to confirm the persona's interest in the proposed jobs and their proficiency level regarding the required skills. The user repeatedly expresses a preference for roles closer to mechanical diagnosis, indicating a potential mismatch with the listed job descriptions. Additionally, the assistant does not provide clear insights or ask targeted questions to assess the user's fit for the roles effectively.\n",
      "---\n",
      "persona_084\n",
      "The interview does not provide sufficient information to confirm the persona's interest or proficiency level regarding the required skills for the job. The user expresses interest but lacks experience and proficiency in the required skills, and there is no further discussion on how the training opportunities will address these gaps.\n",
      "---\n",
      "persona_097\n",
      "The interview does not provide sufficient information to confirm the persona's interest or proficiency level for the proposed jobs. The user's response indicates a preference for hands-on navigation and seamanship roles, which are not directly addressed in the provided job descriptions. Additionally, the user's specific skills and experience related to the required skills for the jobs are not discussed.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "filename = f\"quality_job_feedback_interviews_{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "quality_interviews = read_json(save_path)\n",
    "\n",
    "for persona_id in quality_interviews:\n",
    "    quality = json.loads(quality_interviews[persona_id])\n",
    "    if quality['quality_level'] != 'OK':\n",
    "        print(persona_id)\n",
    "        print(quality['rationale'])\n",
    "        print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95175d8c-5f27-4d33-b3eb-546b8e75e369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaef335b-47de-4657-8bf7-9aec70fedf51",
   "metadata": {},
   "source": [
    "# Translate interviews in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f58c804d-0058-4325-8b20-4f268397cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_interview(\n",
    "    interview,\n",
    "    model: str = \"mistral-small-latest\",\n",
    "    print_prompt=False\n",
    ") -> InterviewInfo:\n",
    "\n",
    "    prompt = TRANSLATE_INTERVIEW_PROMPT.format(\n",
    "        interview=interview\n",
    "    )\n",
    "\n",
    "    if print_prompt is True:\n",
    "        print(prompt)\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model, temperature=0.0)\n",
    "    result = extraction_agent.structured_output(output_model=InterviewInfo, prompt=prompt)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faf0145f-c97b-4f09-9f0f-32e650186e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = f\"interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f8be107-e323-473c-b187-3b4ae4086ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:23<14:05,  9.29s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tool calls found in response",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m new_items_processed \u001b[38;5;241m=\u001b[39m new_items_processed \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     17\u001b[0m interview \u001b[38;5;241m=\u001b[39m interviews[interview_id]\n\u001b[0;32m---> 19\u001b[0m translated_interview \u001b[38;5;241m=\u001b[39m \u001b[43mtranslate_interview\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterview\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m en_interviews[interview_id] \u001b[38;5;241m=\u001b[39m translated_interview\u001b[38;5;241m.\u001b[39minterview\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_items_processed \u001b[38;5;241m%\u001b[39m cache_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mtranslate_interview\u001b[0;34m(interview, model, print_prompt)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[1;32m     14\u001b[0m extraction_agent \u001b[38;5;241m=\u001b[39m get_agent(model_id\u001b[38;5;241m=\u001b[39mmodel, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mextraction_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mInterviewInfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:468\u001b[0m, in \u001b[0;36mAgent.structured_output\u001b[0;34m(self, output_model, prompt)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    467\u001b[0m     future \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39msubmit(execute)\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opentelemetry/instrumentation/threading/__init__.py:171\u001b[0m, in \u001b[0;36mThreadingInstrumentor.__wrap_thread_pool_submit.<locals>.wrapped_func\u001b[0;34m(*func_args, **func_kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     token \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mattach(otel_context)\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:464\u001b[0m, in \u001b[0;36mAgent.structured_output.<locals>.execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_output_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/runners.py:44\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         loop\u001b[38;5;241m.\u001b[39mset_debug(debug)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/asyncio/base_events.py:649\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m    647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/agent/agent.py:516\u001b[0m, in \u001b[0;36mAgent.structured_output_async\u001b[0;34m(self, output_model, prompt)\u001b[0m\n\u001b[1;32m    511\u001b[0m     structured_output_span\u001b[38;5;241m.\u001b[39madd_event(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgen_ai.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.message\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    513\u001b[0m         attributes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: serialize(message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])},\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    515\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mstructured_output(output_model, temp_messages, system_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msystem_prompt)\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, TypedEvent):\n\u001b[1;32m    518\u001b[0m         event\u001b[38;5;241m.\u001b[39mprepare(invocation_state\u001b[38;5;241m=\u001b[39m{})\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/strands/models/mistral.py:548\u001b[0m, in \u001b[0;36mMistralModel.structured_output\u001b[0;34m(self, output_model, prompt, system_prompt, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (json\u001b[38;5;241m.\u001b[39mJSONDecodeError, \u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to parse tool call arguments into model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tool calls found in response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: No tool calls found in response"
     ]
    }
   ],
   "source": [
    "cache_period = 5\n",
    "\n",
    "filename = f\"en_interviews_{interview_data_version}.json\"\n",
    "save_path = DATA_INTERVIEWS_DIR / filename\n",
    "if not save_path.exists():\n",
    "    save_json(save_path, {})\n",
    "en_interviews = read_json(save_path)\n",
    "\n",
    "\n",
    "new_items_processed = 0\n",
    "for interview_id in tqdm(interviews):\n",
    "    if interview_id in en_interviews:\n",
    "        continue\n",
    "\n",
    "    new_items_processed = new_items_processed + 1\n",
    "    \n",
    "    interview = interviews[interview_id]\n",
    "\n",
    "    translated_interview = translate_interview(interview, print_prompt=False)\n",
    "    en_interviews[interview_id] = translated_interview.interview\n",
    "\n",
    "    if new_items_processed % cache_period == 0:\n",
    "        save_json(save_path, en_interviews)\n",
    "\n",
    "    # if new_items_processed > 4:break\n",
    "\n",
    "save_json(save_path, en_interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b635659-4924-43c5-8f67-0320cfa938df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 50.71it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "831c9dbe-20d3-4b0a-8c08-bcf484701ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persona_086\n",
      "The interview does not provide sufficient information to extract all the required persona details. The user is not looking for a job or training, so only the age is important to know (below 16 or not), which is not provided.\n",
      "---\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63ceb360-74a7-46c0-9847-84e82377d58e",
   "metadata": {},
   "source": [
    "# Redo interview of a Persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57074888-f1aa-4b15-900e-945e20a1a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤 Conduct Interview...\n",
      "Assistant: Hello, I'm here to helping you navigate your career path.\n",
      "To do so effectively, I may need to collect some personal information — rest assured, your privacy is fully respected and protected.\n",
      "User: Too early for career. Training first.\n",
      "\n",
      "Which tools? Simple ones. No personal info. Please.\n",
      "Assistant: Understood. Let’s focus on training interests.\n",
      "\n",
      "1. What **domain** interests you for training? Here are the options:\n",
      "   - Financial Risk Management And Compliance\n",
      "   - Electrical And Electronic Systems Engineering\n",
      "   - Food Safety And Management\n",
      "   - Fiber And Paper Industry Operations\n",
      "   - Industrial Equipment Maintenance And Optimization\n",
      "   - Procurement And Supply Chain Management\n",
      "   - Hospitality And Tourism Management\n",
      "   - Legal Practice And Advocacy\n",
      "   - Maritime And Port Operations Management\n",
      "   - Visual And Artistic Skills\n",
      "   - Information Management And Digital Security\n",
      "   - Live Event Technical Management\n",
      "\n",
      "2. Do you want to share your **current city** (helps match local/online options)?\n",
      "\n",
      "*(No personal details beyond this—just training focus.)*\n",
      "\n",
      "User: Design Research Studies and Development.\n",
      "\n",
      "City: Brasília.\n",
      "\n",
      "Training only.\n",
      "Assistant: Thank you. To clarify:\n",
      "\n",
      "1. Did you mean **\"Design Research and Innovation Management\"** (from the list)?\n",
      "2. What’s your **highest completed education level**? Options:\n",
      "   - Ensino Fundamental / Médio / Técnico / Tecnólogo / Graduação / Bacharelado / Licenciatura / Pós-graduação / Especialização / Mestrado / MBA / Doutorado\n",
      "\n",
      "*(No other personal details needed.)*\n",
      "\n",
      "User: No.\n",
      "\n",
      "Design Research Studies and Development.\n",
      "\n",
      "Education: Ensino Fundamental.\n",
      "\n",
      "—\n",
      "Math → logic.\n",
      "Cinema → ideas.\n",
      "Assistant: Confirmed:\n",
      "\n",
      "- **Interest**: Training only\n",
      "- **Domain**: *Not in current list* (I’ll note \"Design Research Studies and Development\" as your preference)\n",
      "- **City**: Brasília\n",
      "- **Education**: Ensino Fundamental\n",
      "\n",
      "**Skills** (optional but helpful for training matches):\n",
      "Do you have experience with any of these? If yes, rate your proficiency (**None/Basic/Intermediate/Advanced**):\n",
      "- Drawing/sketching\n",
      "- Digital tools (e.g., Canva, Photoshop)\n",
      "- Writing/ideation (e.g., scripts, concepts)\n",
      "- Math/logic (as you mentioned)\n",
      "\n",
      "*(Last step—then I’ll summarize for your confirmation.)*\n",
      "\n",
      "User: None.\n",
      "\n",
      "Basic:\n",
      "- Math/logic\n",
      "- Sketching (paper)\n",
      "\n",
      "—\n",
      "Training? Which options?\n",
      "Assistant: **Training options** in closest domains to your interest:\n",
      "1. **Visual And Artistic Skills** (drawing, design basics)\n",
      "2. **Information Management And Digital Security** (logic/structure)\n",
      "3. *No direct match for \"Design Research Studies and Development\"* (noted).\n",
      "\n",
      "---\n",
      "**Summary for your confirmation**:\n",
      "- **Name**: [Not provided]\n",
      "- **Age**: [Not provided] *(Important: Are you under 16? If yes, some programs have age restrictions.)*\n",
      "- **City**: Brasília\n",
      "- **Interest**: Training only\n",
      "- **Target domain**: Design Research Studies and Development *(not in current list; closest: Visual And Artistic Skills)*\n",
      "- **Education**: Ensino Fundamental\n",
      "- **Skills**:\n",
      "  - Math/Logic: **Basic**\n",
      "  - Sketching (paper): **Basic**\n",
      "\n",
      "**Please confirm or correct**. If complete, reply with *\"Sim\"* or *\"Correto\"*.\n",
      "\n",
      "User: Correto.\n",
      "\n",
      "Under 16.\n",
      "\n",
      "—\n",
      "Training:\n",
      "- Prototyping 101?\n",
      "- Basic Coding?\n",
      "\n",
      "No jobs. Just try.\n",
      "Assistant: **Final Summary**:\n",
      "- **Age**: Under 16 *(noted for youth-focused programs)*\n",
      "- **City**: Brasília\n",
      "- **Interest**: Training only *(no jobs)*\n",
      "- **Target domains**:\n",
      "  1. Prototyping basics *(closest: **Visual And Artistic Skills**)*\n",
      "  2. Basic coding *(closest: **Information Management And Digital Security**—intro logic/tech)*\n",
      "- **Education**: Ensino Fundamental\n",
      "- **Skills**:\n",
      "  - Math/Logic: Basic\n",
      "  - Sketching (paper): Basic\n",
      "\n",
      "**Correto?** *(Last confirmation before closing.)*\n",
      "\n",
      "---\n",
      "*(After your \"Sim,\" I’ll end with the completion code.)*\n",
      "\n",
      "User: Sim.\n",
      "\n",
      "—\n",
      "Prototyping 101.\n",
      "Basic Coding.\n",
      "\n",
      "Design Research Studies and Development.\n",
      "Training.\n",
      "Assistant: **INTERVIEW_COMPLETE: Profile ready for processing.**\n",
      "\n",
      "*(Nota: Seu interesse em \"Design Research Studies and Development\" foi registrado, mas as opções atuais mais próximas são **Visual And Artistic Skills** para prototipagem e **Information Management** para lógica/coding básico.)*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "persona_id = \"persona_073\"\n",
    "\n",
    "activity_domains_str = \"\"\n",
    "first = True\n",
    "for domain in jobs_map:\n",
    "    if first is False:\n",
    "        activity_domains_str += \", \"\n",
    "    activity_domains_str += domain\n",
    "    first = False\n",
    "    \n",
    "skill_domains_str = \"\"\n",
    "first = True\n",
    "for domain in trainings_map:\n",
    "    if first is False:\n",
    "        skill_domains_str += \", \"\n",
    "    skill_domains_str += domain\n",
    "    first = False\n",
    "\n",
    "# Interview\n",
    "print(\"🎤 Conduct Interview...\")\n",
    "conversation = conduct_persona_interview(persona_id, activity_domains_str, skill_domains_str, max_turns=10, print_conversation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb894d33-2d1c-41c1-93fa-73677f3bd160",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"interviews_{interview_data_version}.json\"\n",
    "interviews_save_path = DATA_INTERVIEWS_DIR / filename\n",
    "interviews = read_json(interviews_save_path)\n",
    "interviews[persona_id] = conversation\n",
    "save_json(interviews_save_path, interviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427eb2d-05ff-420a-b30d-3c2ea7319e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
